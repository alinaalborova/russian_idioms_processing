{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17/05 MICE - Token-Level - multiBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMspeB6RlfXEYBKj3BDMagj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinaalborova/russian_idioms_processing/blob/main/MICE_Token_Level_multiBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n5x1wCqtCTH"
      },
      "source": [
        "# Idiom Type and Token Classification\n",
        "\n",
        "Based on [MICE: Mining Idioms with Contextual Embeddings](https://arxiv.org/pdf/2008.05759.pdf) by  Škvorc et al.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7tUrqp827WI"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgVfmFGl296R",
        "outputId": "a3bfaeae-2a30-4c1e-d0d2-3acdf290714a"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensor2tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.9MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Collecting tensor2tensor\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/7c/9e87d30cefad5cbc390bb7f626efb3ded9b19416b8160f1a1278da81b218/tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.0.1)\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (2.23.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (7.1.2)\n",
            "Requirement already satisfied: dopamine-rl in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.0.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.41.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.15.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.12.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (2.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.7.1)\n",
            "Collecting bz2file\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 33.5MB/s \n",
            "\u001b[?25hCollecting kfac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/36/06fe2c757044bb51906fef231ac48cc5bf9a277fc9a8c7e1108d7e9e8cfd/kfac-0.2.3-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 38.2MB/s \n",
            "\u001b[?25hCollecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.19.5)\n",
            "Collecting mesh-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/10/37df0bc87ebf84e1414613176340e3aadc3697d2bd112bf63d3d4b1e848a/mesh_tensorflow-0.1.19-py3-none-any.whl (366kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 37.0MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.3)\n",
            "Collecting tensorflow-gan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.17.3)\n",
            "Collecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.2.30)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (5.1.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (3.12.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (21.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.1.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.30.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tensor2tensor) (2.7.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (1.24.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (8.0.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (2.0.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.30.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.17.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->tensor2tensor) (1.2.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->tensor2tensor) (56.1.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gan->tensor2tensor) (0.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor) (1.5.0)\n",
            "Requirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent->tensor2tensor) (1.1.0)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 40.9MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tensor2tensor) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tensor2tensor) (1.53.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->tensor2tensor) (2.0.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client->tensor2tensor) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (2.4.7)\n",
            "Building wheels for collected packages: bz2file, pypng\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-cp37-none-any.whl size=6884 sha256=c66fe043f0590917686378fe764fac283021fef994d61347aa536cbe29da811d\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp37-none-any.whl size=67163 sha256=6807f9856dd4b2b576aa99dd4c85be393bb60e944fb8ef3787be59f63618f74c\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "Successfully built bz2file pypng\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-addons, tf-slim, bz2file, tensorflow-probability, kfac, pypng, mesh-tensorflow, gunicorn, tensorflow-gan, zope.interface, zope.event, gevent, tensor2tensor\n",
            "  Found existing installation: tensorflow-probability 0.12.1\n",
            "    Uninstalling tensorflow-probability-0.12.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.12.1\n",
            "Successfully installed bz2file-0.98 gevent-21.1.2 gunicorn-20.1.0 kfac-0.2.3 mesh-tensorflow-0.1.19 pypng-0.0.20 tensor2tensor-1.15.7 tensorflow-addons-0.13.0 tensorflow-gan-2.0.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlDZpk7oLnm-"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Activation, Concatenate, Masking, GRU\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import tensorflow as tf\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ07_hgeCG7N"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGdFYdryCFnx",
        "outputId": "7dda7ca3-81f1-4e46-96d3-c8dc04219049"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_LXZJEgCP1I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "86bd43c4-0817-466c-9055-cf0842389cd4"
      },
      "source": [
        "dataset_vnc_dir = '/content/drive/MyDrive/ВКР/Sense Disambiguation Corpus/token_level_vnc_multiBERT.csv'\n",
        "data_vnc = pd.read_csv(dataset_vnc_dir )\n",
        "data_vnc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context ID</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Idiom Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>Он</td>\n",
              "      <td>2</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>0</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.31914854 -0.5246461   0.69526...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>бил</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>0</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.28880197 -0.0534335   0.75770...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                    Token Embedding\n",
              "0           0  ...  tf.Tensor(\\n[[ 0.31914854 -0.5246461   0.69526...\n",
              "1           1  ...  tf.Tensor(\\n[[ 0.28880197 -0.0534335   0.75770...\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA-TbZxOLz0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "1161cc12-bd0d-4efd-d553-73c6c613e3d0"
      },
      "source": [
        "data_vnc.drop(data_vnc.iloc[:, :2], axis=1, inplace=True)\n",
        "data_vnc.drop('Context ID', axis=1, inplace=True)\n",
        "data_vnc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Idiom Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>Он</td>\n",
              "      <td>2</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.31914854 -0.5246461   0.69526...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>бил</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.28880197 -0.0534335   0.75770...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 1.08091556e-01 -1.02390237e-01 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>за</td>\n",
              "      <td>2</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.01611326 -0.16018972  0.31805...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>картой</td>\n",
              "      <td>2</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.05653494  0.06898555  0.74265...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                    Token Embedding\n",
              "0   бить карту  ...  tf.Tensor(\\n[[ 0.31914854 -0.5246461   0.69526...\n",
              "1   бить карту  ...  tf.Tensor(\\n[[ 0.28880197 -0.0534335   0.75770...\n",
              "2   бить карту  ...  tf.Tensor(\\n[[ 1.08091556e-01 -1.02390237e-01 ...\n",
              "3   бить карту  ...  tf.Tensor(\\n[[-0.01611326 -0.16018972  0.31805...\n",
              "4   бить карту  ...  tf.Tensor(\\n[[-0.05653494  0.06898555  0.74265...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWbTSEvZcBFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e49dafa-0675-4118-beca-620df6e34655"
      },
      "source": [
        "data_vnc.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    16711\n",
              "1     1000\n",
              "0      988\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX3x1pJbvQB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22777372-77fe-48a4-9cd2-a54250554f0b"
      },
      "source": [
        "data_vnc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18699, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBUS3mxovE9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770c8765-4704-4b7d-8502-e4c407061f06"
      },
      "source": [
        "len(data_vnc['Idiom Normal'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1__zN0o2bMHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "2fbd68c8-fcf1-49be-c2ff-711a122ab170"
      },
      "source": [
        "dataset_anc_dir = '/content/drive/MyDrive/ВКР/Sense Disambiguation Corpus/token_level_anc_multiBERT.csv'\n",
        "data_anc = pd.read_csv(dataset_anc_dir )\n",
        "data_anc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>С</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.33673236  0.01402963  0.46577...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>бурной</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.13988337 -0.36430976  0.67115...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                    Token Embedding\n",
              "0           0  ...  tf.Tensor(\\n[[ 0.33673236  0.01402963  0.46577...\n",
              "1           1  ...  tf.Tensor(\\n[[ 0.13988337 -0.36430976  0.67115...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "sK48fZrlMNm4",
        "outputId": "266b6fd3-c5bb-45e4-ce2f-d18c7a40ce31"
      },
      "source": [
        "data_anc.drop(data_anc.iloc[:, :2], axis=1, inplace=True)\n",
        "data_anc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>С</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.33673236  0.01402963  0.46577...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>бурной</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.13988337 -0.36430976  0.67115...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>быстротой</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.07310043 -0.16848688  0.36059...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>возможной</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.11816832 -0.15271866  0.21041...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>только</td>\n",
              "      <td>2</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.04656217 -0.15822835 -0.39671...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.18717647 -0.294104    0.31264...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Idiom Normal  ...                                    Token Embedding\n",
              "0  избитая дорога  ...  tf.Tensor(\\n[[ 0.33673236  0.01402963  0.46577...\n",
              "1  избитая дорога  ...  tf.Tensor(\\n[[ 0.13988337 -0.36430976  0.67115...\n",
              "2  избитая дорога  ...  tf.Tensor(\\n[[ 0.07310043 -0.16848688  0.36059...\n",
              "3  избитая дорога  ...  tf.Tensor(\\n[[ 0.11816832 -0.15271866  0.21041...\n",
              "4  избитая дорога  ...  tf.Tensor(\\n[[ 0.18717647 -0.294104    0.31264...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBToZl7vtLeo",
        "outputId": "5414148a-f45d-48d2-8bcc-3f80cc8bf9c6"
      },
      "source": [
        "data_anc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "больное место                 1170\n",
              "болевая точка                 1141\n",
              "правая рука                   1114\n",
              "путеводная звезда              998\n",
              "нож острый                     971\n",
              "лавровый венок                 939\n",
              "бедный родственник             904\n",
              "зелёная улица                  786\n",
              "вавилонское столпотворение     774\n",
              "тяжёлая рука                   656\n",
              "наша сестра                    638\n",
              "ваш брат                       587\n",
              "дальний прицел                 573\n",
              "старый воробей                 556\n",
              "пороховая бочка                554\n",
              "чёрная кость                   505\n",
              "синяя птица                    462\n",
              "заблудшая овца                 438\n",
              "красная бумажка                412\n",
              "вторая ступень                 400\n",
              "девичья кожа                   373\n",
              "старый гриб                    304\n",
              "другой разговор                279\n",
              "долгая песня                   257\n",
              "музейная редкость              219\n",
              "избитая дорога                 212\n",
              "маковое зерно                  193\n",
              "ободранная кошка               187\n",
              "куриная голова                 154\n",
              "чернильная строка               47\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gLTJiitUym",
        "outputId": "c5037a94-b3ee-43a9-b488-8df43734bb5c"
      },
      "source": [
        "len(data_anc['Idiom Normal'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "6kSMItV0er4B",
        "outputId": "5bfedb5c-8d90-401d-ecd0-5c1660a197af"
      },
      "source": [
        "data = pd.concat([data_vnc, data_anc], ignore_index=True)\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Idiom Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>Он</td>\n",
              "      <td>2</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.31914854 -0.5246461   0.69526...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>бил</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.02800624 -0.18069455  0.26622...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.28880197 -0.0534335   0.75770...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                    Token Embedding\n",
              "0   бить карту  ...  tf.Tensor(\\n[[ 0.31914854 -0.5246461   0.69526...\n",
              "1   бить карту  ...  tf.Tensor(\\n[[ 0.28880197 -0.0534335   0.75770...\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "RTjCivomgQsz",
        "outputId": "b7f0e487-a334-481d-8ddd-67a36937da97"
      },
      "source": [
        "data.tail(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Idiom Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35500</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедных родственниках</td>\n",
              "      <td>бедных</td>\n",
              "      <td>0</td>\n",
              "      <td>[Егор Дмитрич Глумов, муж]   У молодой женщин...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.2779434   0.15737975 -0.09745...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.00859448 -0.20205446  0.63864...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35501</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедных родственниках</td>\n",
              "      <td>родственниках</td>\n",
              "      <td>0</td>\n",
              "      <td>[Егор Дмитрич Глумов, муж]   У молодой женщин...</td>\n",
              "      <td>tf.Tensor(\\n[[-0.2779434   0.15737975 -0.09745...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.0848169  -0.22677557  0.73319...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Idiom Normal  ...                                    Token Embedding\n",
              "35500  бедный родственник  ...  tf.Tensor(\\n[[ 0.00859448 -0.20205446  0.63864...\n",
              "35501  бедный родственник  ...  tf.Tensor(\\n[[ 0.0848169  -0.22677557  0.73319...\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUH7P_6n3S7a"
      },
      "source": [
        "## Embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzdkAja53UYL"
      },
      "source": [
        "### Load BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WEtg6rP3R4f",
        "outputId": "87cda592-7854-4391-eb57-d1351d060d3d"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.TFBertModel, ppb.BertTokenizer, 'bert-base-multilingual-cased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BERT_model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqovw-mS3XP_"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def pad_sentence(tokenized, max_len):\n",
        "  print('\\nPadding/truncating all sentences to %d values...' % max_len)\n",
        "  print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "  # Pad our input tokens with value 0.\n",
        "  # \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "  # as opposed to the beginning.\n",
        "  input_ids = pad_sequences(tokenized, maxlen=max_len, dtype=\"long\", \n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "  print('\\nDone.')\n",
        "  return input_ids\n",
        "\n",
        "def create_att_masks(input_ids):\n",
        "  # Create attention masks\n",
        "  attention_masks = []\n",
        "\n",
        "  # For each sentence...\n",
        "  for sent in input_ids:\n",
        "      \n",
        "      # Create the attention mask.\n",
        "      #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "      #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "      att_mask = [int(token_id > 0) for token_id in sent]\n",
        "      \n",
        "      # Store the attention mask for this sentence.\n",
        "      attention_masks.append(att_mask)\n",
        "  attention_masks = np.array(attention_masks)    \n",
        "  return attention_masks\n",
        "\n",
        "def extract_full_embeddings(output):\n",
        "  last_hidden_states = output[0] # lhs for all sentences\n",
        "  extracted = []\n",
        "  for i, el in enumerate(last_hidden_states): #for each sentence...\n",
        "    extracted.append(last_hidden_states[i]) \n",
        "  return extracted\n",
        "\n",
        "def use_batches(padded, masked):\n",
        "  full_embeddings = []\n",
        "\n",
        "  NUM_OF_IDIOMS_initial = len(masked)\n",
        "  BATCH_SIZE = 200  # Using larger batch might kill the session when embedding contexts\n",
        "  NUM_OF_IDIOMS = NUM_OF_IDIOMS_initial\n",
        "  i = 0\n",
        "\n",
        "  while NUM_OF_IDIOMS > 0:\n",
        "    print(i)\n",
        "    NUM_OF_IDIOMS -= BATCH_SIZE\n",
        "    print('NUM_OF_IDIOMS -= BATCH_SIZE', NUM_OF_IDIOMS)\n",
        "    if i < NUM_OF_IDIOMS_initial - BATCH_SIZE:\n",
        "      output_batch = BERT_model(padded[i:i+BATCH_SIZE], attention_mask = masked[i:i+BATCH_SIZE])\n",
        "    else:\n",
        "      output_batch = BERT_model(padded[i:NUM_OF_IDIOMS_initial], attention_mask = masked[i:NUM_OF_IDIOMS_initial])\n",
        "    i += BATCH_SIZE\n",
        "    embeddings_batch = extract_full_embeddings(output_batch)\n",
        "    full_embeddings.append(embeddings_batch)\n",
        "\n",
        "  full_embeddings_all = []\n",
        "  for batch in full_embeddings:\n",
        "    for sentence in batch:\n",
        "      full_embeddings_all.append(sentence)\n",
        "\n",
        "  return full_embeddings_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhEfUvMDCJiH"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4_lb8Xr-0jW"
      },
      "source": [
        "MAX_CONTEXT_LEN = 220\n",
        "MAX_TOKEN_LEN = 15\n",
        "VECTOR_DIM = 768\n",
        "NUM_CLASSES = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-geAYheaEgWb",
        "outputId": "cf5c21a3-246c-4697-e905-6ce86a2f49c9"
      },
      "source": [
        "def build_model():\n",
        "    input_token = Input(shape=(MAX_TOKEN_LEN, VECTOR_DIM), name='input1')\n",
        "    input_context = Input(shape=(MAX_CONTEXT_LEN,VECTOR_DIM), name='input2')\n",
        "\n",
        "    #token\n",
        "    forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "    backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "    bidirectional1 = Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_TOKEN_LEN,VECTOR_DIM))(input_token)\n",
        "\n",
        "    #context\n",
        "    bidirectional2 = Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_CONTEXT_LEN,VECTOR_DIM))(input_context)\n",
        "\n",
        "    concat = Concatenate(axis=1)([bidirectional1, bidirectional2])\n",
        "\n",
        "    dense = Dense(NUM_CLASSES)(concat)\n",
        "    softmax = Activation('softmax', name='output')(dense)\n",
        "\n",
        "    model = Model(inputs=[input_token, input_context], outputs=softmax)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    plot_model(model, to_file='multiple_inputs.png')\n",
        "    return model\n",
        "model_all = build_model()\n",
        "\n",
        "model_all.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             [(None, 5, 768)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input2 (InputLayer)             [(None, 200, 768)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20)           46800       input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 20)           46800       input2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 40)           0           bidirectional[0][0]              \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 3)            123         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Activation)             (None, 3)            0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 70,323\n",
            "Trainable params: 70,323\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Qtz4jxj685"
      },
      "source": [
        "## VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdwe4uLQBzCB"
      },
      "source": [
        "tokens_vnc = data_vnc['Token'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_vnc = data_vnc['Context'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_token_length_vnc = max([len(sen) for sen in tokens_vnc])\n",
        "max_context_length_vnc = max([len(sen) for sen in tokenized_contexts_vnc])\n",
        "print('Max token length: ', max_token_length_vnc)\n",
        "print('Max context length: ', max_context_length_vnc)\n",
        "\n",
        "padded_tokens_vnc = pad_sentence(tokens_vnc, max_token_length_vnc+5)\n",
        "padded_contexts_vnc = pad_sentence(tokenized_contexts_vnc, max_context_length_vnc+20)\n",
        "print(len(padded_tokens_vnc))\n",
        "print(len(padded_contexts_vnc))\n",
        "\n",
        "masked_tokens_vnc = create_att_masks(padded_tokens_vnc)\n",
        "masked_contexts_vnc = create_att_masks(padded_contexts_vnc)\n",
        "print(len(masked_tokens_vnc))\n",
        "print(len(masked_contexts_vnc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91S3LkK0CUpM"
      },
      "source": [
        "padded_tokens_vnc_train, padded_tokens_vnc_test = train_test_split(padded_tokens_vnc, test_size=0.3, random_state=34)\n",
        "masked_tokens_vnc_train, masked_tokens_vnc_test = train_test_split(masked_tokens_vnc, test_size=0.3, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSQQ7oQJCm92"
      },
      "source": [
        "embedded_tokens_vnc = use_batches(padded_tokens_vnc_train, padded_tokens_vnc_train)\n",
        "len(embedded_tokens_vnc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCV1SwAWEtS3"
      },
      "source": [
        "embedded_tokens_vnc_test = use_batches(padded_tokens_vnc_test, padded_tokens_vnc_test)\n",
        "len(embedded_tokens_vnc_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmffJPDOEMqq"
      },
      "source": [
        "padded_contexts_vnc_train, padded_contexts_vnc_test = train_test_split(padded_contexts_vnc, test_size=0.3, random_state=34)\n",
        "masked_contexts_vnc_train, masked_contexts_vnc_test = train_test_split(masked_contexts_vnc, test_size=0.3, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF_1U6f3Hitt"
      },
      "source": [
        "embedded_contexts_vnc_train = use_batches(padded_contexts_vnc_train, masked_contexts_vnc_train)\n",
        "len(embedded_contexts_vnc_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GXFqyVFPtlk"
      },
      "source": [
        "contexts_unique_vnc = list(set(data_vnc.Context.values))\n",
        "len(contexts_unique_vnc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QwY9NEIPxQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b195d8-dc22-465b-d4ed-84ee7d509eee"
      },
      "source": [
        "#tokenized_contexts = [tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=200) for x in contexts_unique]\n",
        "tokenized_contexts_vnc = [tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=200) for x in contexts_unique_vnc]\n",
        "max_context_length = max([len(sen) for sen in tokenized_contexts_vnc])\n",
        "print('Max context length: ', max_context_length)\n",
        "\n",
        "padded_contexts_vnc = pad_sentence(tokenized_contexts_vnc, max_context_length+20)\n",
        "print(len(padded_contexts_vnc))\n",
        "\n",
        "masked_contexts_vnc = create_att_masks(padded_contexts_vnc)\n",
        "print(len(masked_contexts_vnc))\n",
        "\n",
        "embedded_contexts_vnc = use_batches(padded_contexts_vnc, masked_contexts_vnc)\n",
        "len(embedded_contexts_vnc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max context length:  200\n",
            "\n",
            "Padding/truncating all sentences to 220 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "892\n",
            "892\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 692\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 492\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 292\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 92\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQkTNiV9iQT4",
        "outputId": "a8d83443-4a1a-4eb6-a773-05e3624d5be3"
      },
      "source": [
        "len(embedded_contexts_vnc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayrvi6D5dqI1"
      },
      "source": [
        "data_vnc['Token Embedding'] = embedded_tokens_vnc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_xzNM2ihTQ"
      },
      "source": [
        "embeddings_per_token_vnc.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "tdI2YIT1QsLk",
        "outputId": "66695eec-41fd-46bb-92cc-748c8b2ea2ef"
      },
      "source": [
        "examples_per_tokens_vnc = data_vnc.Context.values\n",
        "# RAM CRASHES if using array instead of list\n",
        "# embeddings_per_token_vnc = np.empty(shape=(len(embedded_tokens_vnc), MAX_CONTEXT_LEN+20, 768), dtype=object)\n",
        "embeddings_per_token_vnc = []\n",
        "for i, context in enumerate(examples_per_tokens_vnc):\n",
        "  if context in contexts_unique_vnc:\n",
        "    embeddings_per_token_vnc.append(embedded_contexts_vnc[contexts_unique_vnc.index(context)])\n",
        "    #embeddings_per_token_vnc[i] = embedded_contexts_vnc[contexts_unique_vnc.index(context)]\n",
        "\n",
        "len(embeddings_per_token_vnc)\n",
        "\n",
        "data_vnc['Context Embedding'] = embeddings_per_token_vnc\n",
        "data_vnc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Token</th>\n",
              "      <th>Label</th>\n",
              "      <th>Context</th>\n",
              "      <th>Context Embedding</th>\n",
              "      <th>Idiom Embedding</th>\n",
              "      <th>Token Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>Он</td>\n",
              "      <td>2</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>((tf.Tensor(-0.028006509, shape=(), dtype=floa...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>((tf.Tensor(0.31914937, shape=(), dtype=float3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>бил</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "      <td>((tf.Tensor(-0.028006509, shape=(), dtype=floa...</td>\n",
              "      <td>tf.Tensor(\\n[[ 0.1000824  -0.18658537  0.44111...</td>\n",
              "      <td>((tf.Tensor(0.2888023, shape=(), dtype=float32...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                    Token Embedding\n",
              "0   бить карту  ...  ((tf.Tensor(0.31914937, shape=(), dtype=float3...\n",
              "1   бить карту  ...  ((tf.Tensor(0.2888023, shape=(), dtype=float32...\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrdp7OElmE1o"
      },
      "source": [
        "X = [embedded_tokens_vnc, embeddings_per_token_vnc]\n",
        "labels_vnc = to_categorical(data_vnc.Label)\n",
        "X_train_vnc, X_test_vnc = train_test_split(X, test_size=0.3, random_state=34)\n",
        "Y_train_vnc, Y_test_vnc = train_test_split(labels_vnc, test_size=0.3, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEVeb2BbX1Kd",
        "outputId": "722f7bf1-11cd-4391-9d7d-7d60014259a4"
      },
      "source": [
        "data_vnc['Token Embedding'].shape\n",
        "len(list(data_vnc['Token Embedding'])[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlV7MmXPYhlb"
      },
      "source": [
        "tokens = data_vnc['Token Embedding'].values\n",
        "contexts = data_vnc['Context Embedding'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H4GbpTTnM8R"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzhB5L6gnPPm",
        "outputId": "148991f1-eaa4-488f-f125-869e13f135b0"
      },
      "source": [
        "model_vnc = build_model()\n",
        "\n",
        "model_vnc.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input1 (InputLayer)             [(None, 15, 768)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input2 (InputLayer)             [(None, 220, 768)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 20)           46800       input1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 20)           46800       input2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 40)           0           bidirectional_2[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            123         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "output (Activation)             (None, 3)            0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 70,323\n",
            "Trainable params: 70,323\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk__w9OGPwLk",
        "outputId": "aef9b3c8-01a0-4e36-9802-43854489d811"
      },
      "source": [
        "len(embedded_tokens_vnc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yac0ukq9U4cT",
        "outputId": "7cc30fb3-e85b-4d88-e690-a44f02a66a69"
      },
      "source": [
        "len(embedded_tokens_vnc[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVNpuIQFWQAU",
        "outputId": "136c62e8-4261-4992-ccec-049e4e614a4b"
      },
      "source": [
        "labels_vnc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18699, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSSdqK8UjIe"
      },
      "source": [
        "for i, el in enumerate(embedded_contexts_vnc):\n",
        "  if len(el) != 220:\n",
        "    print(len(el), i) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIwfrSdMajHh"
      },
      "source": [
        "contexts_array = np.asarray(embedded_contexts_vnc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oE8YPKMaw1Q",
        "outputId": "6f8fc3ba-9d4e-4cde-d1fb-983774d532e2"
      },
      "source": [
        "contexts_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(892, 220, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcw1sCy9vu1B",
        "outputId": "49725d1b-78e4-4599-eceb-4d35cba4d71e"
      },
      "source": [
        "len(embedded_contexts_vnc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMo5AkzgwIiV",
        "outputId": "c218fc2a-ad58-4774-c6a9-c4591d310c41"
      },
      "source": [
        "len(tokens_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e36qyQUkhYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8eafcb-139e-46b0-8ab9-a5b56571a10e"
      },
      "source": [
        " model_vnc.fit({'input1': tokens_array, 'input2': contexts_array}, \n",
        "               {'output': labels_vnc[:892]}, batch_size=8, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "112/112 [==============================] - 28s 179ms/step - loss: 0.2161 - accuracy: 0.8925\n",
            "Epoch 2/5\n",
            "112/112 [==============================] - 21s 183ms/step - loss: 0.0586 - accuracy: 0.9783\n",
            "Epoch 3/5\n",
            "112/112 [==============================] - 20s 180ms/step - loss: 0.0311 - accuracy: 0.9879\n",
            "Epoch 4/5\n",
            "112/112 [==============================] - 20s 179ms/step - loss: 0.0342 - accuracy: 0.9783\n",
            "Epoch 5/5\n",
            "112/112 [==============================] - 20s 178ms/step - loss: 0.0278 - accuracy: 0.9840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19e57a3a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLwbWdsunZzl"
      },
      "source": [
        "model_vnc.fit(X_train_vnc, Y_train_vnc, batch_size=8, epochs=10)#, validation_split=0.1)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qOoLqWcgkQe",
        "outputId": "c58a6349-2ed5-41b4-f7e6-f91daadeaca5"
      },
      "source": [
        "X_train_vnc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13089, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ym0A8IQgtJE",
        "outputId": "9d041c75-186a-4e85-a1a9-c9201a5c53ef"
      },
      "source": [
        "new = np.asarray(X_train_vnc['Context Embedding'])\n",
        "type(list(new)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bZm3Lv3rFfn",
        "outputId": "66ba99db-a884-42b4-d6a9-73490b3aa115"
      },
      "source": [
        "model_vnc.evaluate(np.asarray(X_test_vnc), Y_test_vnc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 101ms/step - loss: 3.1565 - accuracy: 0.4963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.1564769744873047, 0.4962686598300934]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0n8-q_Th5_g",
        "outputId": "718159db-d827-4408-dc20-a0523b9ade4a"
      },
      "source": [
        "MAX_SEQUENCE_LEN = 100\n",
        "model_all = Sequential()\n",
        "model_all.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_all.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_all.add(Dense(NUM_CLASSES))\n",
        "model_all.add(Activation('softmax'))\n",
        "\n",
        "model_all.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAHk2whVh8xI"
      },
      "source": [
        "model_vnc.fit(np.asarray(X_train_vnc['Context Embedding']), Y_train_vnc, batch_size=8, epochs=10)#, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABSFxZNrNz0"
      },
      "source": [
        "## ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPeExIsgIG2s"
      },
      "source": [
        "tokens_anc = data_anc['Token'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_anc = data_anc['Context'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_token_length_anc = max([len(sen) for sen in tokens_anc])\n",
        "max_context_length_anc = max([len(sen) for sen in tokenized_contexts_anc])\n",
        "print('Max token length: ', max_token_length_anc)\n",
        "print('Max context length: ', max_context_length_anc)\n",
        "\n",
        "padded_tokens_anc = pad_sentence(tokens_anc, max_token_length_anc+5)\n",
        "padded_contexts_anc = pad_sentence(tokenized_contexts_anc, max_context_length_anc+20)\n",
        "print(len(padded_tokens_anc))\n",
        "print(len(padded_contexts_anc))\n",
        "\n",
        "masked_tokens_anc = create_att_masks(padded_tokens_anc)\n",
        "masked_contexts_anc = create_att_masks(padded_contexts_anc)\n",
        "print(len(masked_tokens_anc))\n",
        "print(len(masked_contexts_anc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEZOe1q8sfQc"
      },
      "source": [
        "labels_anc = to_categorical(data_anc.Label)\n",
        "X_train_anc, X_test_anc = train_test_split(embedded_contexts_anc, test_size=0.3, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2uoYzhZsneO"
      },
      "source": [
        "Y_train_anc, Y_test_anc = train_test_split(labels_anc, test_size=0.3, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8vv7_Zks3ge"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe2LfJxJs2Z6",
        "outputId": "1a8f171c-3b71-426d-e23b-498cb6446740"
      },
      "source": [
        "model_anc = Sequential()\n",
        "model_anc.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_anc.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_anc.add(Dense(NUM_CLASSES))\n",
        "model_anc.add(Activation('softmax'))\n",
        "\n",
        "model_anc.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_k9TTCfs7hb",
        "outputId": "a0c7d832-824e-4b18-b045-3ab02e7e6d99"
      },
      "source": [
        "model_anc.fit(np.asarray(X_train_anc), Y_train_anc, batch_size=8, epochs=10)#, validation_split=0.1)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "71/71 [==============================] - 23s 217ms/step - loss: 0.6941 - accuracy: 0.5997\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 15s 217ms/step - loss: 0.5749 - accuracy: 0.7476\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.5071 - accuracy: 0.7474\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 0.4704 - accuracy: 0.8011\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 0.4244 - accuracy: 0.8194\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.3700 - accuracy: 0.8511\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.2874 - accuracy: 0.9075\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.2861 - accuracy: 0.9160\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.2041 - accuracy: 0.9544\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.1531 - accuracy: 0.9576\n",
            "fit model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6txZ7eLitC1R",
        "outputId": "90bb693d-2121-4cc4-d75f-95c16a98b645"
      },
      "source": [
        "model_anc.evaluate(np.asarray(X_test_anc), Y_test_anc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "8/8 [==============================] - 4s 96ms/step - loss: 0.6596 - accuracy: 0.7645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6596354246139526, 0.7644628286361694]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEiu6Q9681_n",
        "outputId": "f7ca74c2-9e40-4f66-be8b-0c386e10a527"
      },
      "source": [
        "preds = model_all.predict(np.array(X_test))\n",
        "f1_score(np.argmax(preds, axis=1), np.argmax(Y_test, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7734375000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JqngCkVR0qd",
        "outputId": "bc0fdf8b-ef98-4a30-9057-e5cfe3fa8e38"
      },
      "source": [
        "preds_anc = model_anc.predict(np.array(X_test_anc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Sa67P46Tdp",
        "outputId": "bdce9700-91cb-490c-bada-6b41d5f28965"
      },
      "source": [
        "f1_score(np.argmax(preds_anc, axis=1), np.argmax(Y_test_anc, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7673469387755103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I0ft2T7SCBe",
        "outputId": "87fcbe4e-5788-413b-fa92-03105386e2b2"
      },
      "source": [
        "preds_vnc = model_vnc.predict(np.array(X_test_vnc))\n",
        "f1_score(np.argmax(preds_vnc, axis=1), np.argmax(Y_test_vnc, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5752508361204014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNs0MSsqSJKl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhXwL5WVeoT"
      },
      "source": [
        "# Not Present in the Training Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Zj87_Ee784"
      },
      "source": [
        "## Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9eWLhEyVp2A",
        "outputId": "dd247fc5-2f0a-435d-83a5-d94a568ad8b3"
      },
      "source": [
        "data_anc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "больное место                 57\n",
              "правая рука                   56\n",
              "болевая точка                 52\n",
              "нож острый                    49\n",
              "путеводная звезда             48\n",
              "лавровый венок                44\n",
              "бедный родственник            41\n",
              "зелёная улица                 38\n",
              "тяжёлая рука                  38\n",
              "ваш брат                      34\n",
              "вавилонское столпотворение    30\n",
              "наша сестра                   28\n",
              "пороховая бочка               27\n",
              "дальний прицел                25\n",
              "заблудшая овца                23\n",
              "вторая ступень                23\n",
              "старый воробей                22\n",
              "красная бумажка               21\n",
              "синяя птица                   20\n",
              "долгая песня                  18\n",
              "другой разговор               18\n",
              "старый гриб                   16\n",
              "чёрная кость                  15\n",
              "девичья кожа                  12\n",
              "маковое зерно                 10\n",
              "избитая дорога                10\n",
              "музейная редкость             10\n",
              "куриная голова                 9\n",
              "ободранная кошка               9\n",
              "чернильная строка              3\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHTExiRhXRyn"
      },
      "source": [
        "test_ancs = ['вавилонское столпотворение', 'ободранная кошка', 'наша сестра', 'пороховая бочка', 'дальний прицел', 'заблудшая овца', 'красная бумажка']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh4qK7yGZjgx",
        "outputId": "b721d1cb-cc80-400c-8dc4-79851095e45c"
      },
      "source": [
        "data_anc_test = data_anc.loc[data_anc['Idiom Normal'].isin(test_ancs)]\n",
        "data_anc_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvId2OZLYrTI",
        "outputId": "180dd360-e49e-4502-c148-d7333a8c385e"
      },
      "source": [
        "data_anc_train = data_anc.loc[~data_anc['Idiom Normal'].isin(test_ancs)]\n",
        "data_anc_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(643, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BDhqDI6aDQB",
        "outputId": "e539859d-4920-4f8b-cf4d-bd0f8c73905c"
      },
      "source": [
        "163/806"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2022332506203474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRPthD1wW72U",
        "outputId": "e0d72869-c60a-4f17-a880-fcb0ce7c900a"
      },
      "source": [
        "data_vnc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "бросать тень               53\n",
              "сесть на мель              47\n",
              "пускать корни              41\n",
              "окунуться с головой        31\n",
              "отвести глаза              29\n",
              "давит грудь                29\n",
              "поставить на колени        29\n",
              "выступить на сцену         27\n",
              "приложить руку             27\n",
              "снимать шляпу              27\n",
              "поднять на ноги            27\n",
              "положить голову            25\n",
              "пахнет порохом             23\n",
              "вырвать с корнем           23\n",
              "точить нож                 22\n",
              "преградить дорогу          22\n",
              "вильнуть хвостом           21\n",
              "сидеть на печи             20\n",
              "открыть глаза              20\n",
              "умывать руки               19\n",
              "открывать Америку          19\n",
              "плести кружева             18\n",
              "взваливать на плечи        17\n",
              "имей глаза                 17\n",
              "поддать жару               16\n",
              "разбить лед                16\n",
              "чесать затылок             16\n",
              "прокладывать дорогу        14\n",
              "бросать перо               14\n",
              "прижать хвост              13\n",
              "давать сдачу               13\n",
              "катить бочку               12\n",
              "прищемить хвост            12\n",
              "поймать на удочку          12\n",
              "держать на прицеле         11\n",
              "поднимать пыль             11\n",
              "сделать выставку           10\n",
              "воскурять фимиам            9\n",
              "наступить на мозоль         8\n",
              "попадать в яблочко          8\n",
              "надеть узду                 8\n",
              "ослепить глаза              8\n",
              "задрать хвост               8\n",
              "положить на обе лопатки     7\n",
              "сжигать мосты               6\n",
              "наступать на ногу           6\n",
              "опустить хвост              5\n",
              "посадить на землю           5\n",
              "бить карту                  5\n",
              "поддаться на удочку         4\n",
              "становиться на рельсы       3\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7zwblUbbu5w"
      },
      "source": [
        "test_vncs = ['точить нож', 'преградить дорогу', 'вильнуть хвостом', 'сидеть на печи', \n",
        "             'открыть глаза', 'умывать руки', 'открывать Америку', 'плести кружева', \n",
        "             'положить голову']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKSFFPdKc0qo",
        "outputId": "c78aa848-374c-4a0f-f9d4-2f390797de8e"
      },
      "source": [
        "data_vnc_test = data_vnc.loc[data_vnc['Idiom Normal'].isin(test_vncs)]\n",
        "data_vnc_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll4Gt0JSc9UB",
        "outputId": "24fb4939-32a1-451a-fad4-46dde6fbe4dc"
      },
      "source": [
        "data_vnc_train = data_vnc.loc[~data_vnc['Idiom Normal'].isin(test_ancs)]\n",
        "data_vnc_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VZA1_6wdLaP",
        "outputId": "53bb7bcf-adf3-4085-f254-678f216b8ebe"
      },
      "source": [
        "186/893"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20828667413213886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "xETJpDLEdPeH",
        "outputId": "ed67fafe-3e35-4fec-f18d-475a99cee79e"
      },
      "source": [
        "data_all_train = pd.concat([data_vnc_train, data_anc_train], ignore_index=True)\n",
        "data_all_train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                            Example\n",
              "0   бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1   бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "uIYPXEzXex_y",
        "outputId": "69924d3c-79c8-441e-9b2c-cc107576e1bd"
      },
      "source": [
        "data_all_test = pd.concat([data_vnc_test, data_anc_test], ignore_index=True)\n",
        "data_all_test.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>1</td>\n",
              "      <td>С тех пор от него можно услышать: «Хватит кич...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>0</td>\n",
              "      <td>Впечатление было такое, что мы на судне Колум...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Idiom Normal  ...                                            Example\n",
              "0  открывать Америку  ...   С тех пор от него можно услышать: «Хватит кич...\n",
              "1  открывать Америку  ...   Впечатление было такое, что мы на судне Колум...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_HkcJsOnGA6"
      },
      "source": [
        "## Embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2dWdUcAofJy"
      },
      "source": [
        "### VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfFmbjdnIOI",
        "outputId": "36fef292-ef12-4117-b808-5e46655a9776"
      },
      "source": [
        "tokenized_idioms_vnc_train_not_present = data_vnc_train['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_vnc_train_not_present = data_vnc_train['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_vnc_train_not_present = max([len(sen) for sen in tokenized_idioms_vnc_train_not_present])\n",
        "max_context_length_vnc_train_not_present = max([len(sen) for sen in tokenized_contexts_vnc_train_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_vnc_train_not_present)\n",
        "print('Max context length: ', max_context_length_vnc_train_not_present)\n",
        "\n",
        "padded_idioms_vnc_train_not_present = pad_sentence(tokenized_idioms_vnc_train_not_present, max_idiom_length_vnc_train_not_present+5)\n",
        "padded_contexts_vnc_train_not_present = pad_sentence(tokenized_contexts_vnc_train_not_present, max_context_length_vnc_train_not_present+20)\n",
        "print(len(padded_idioms_vnc_train_not_present))\n",
        "print(len(padded_contexts_vnc_train_not_present))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  234\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 254 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "893\n",
            "893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM0wsxpunn9y",
        "outputId": "a8dacc18-e4fc-46ee-86bc-709894d55d8a"
      },
      "source": [
        "masked_idioms_vnc_train_not_present = create_att_masks(padded_idioms_vnc_train_not_present)\n",
        "masked_contexts_vnc_train_not_present = create_att_masks(padded_contexts_vnc_train_not_present)\n",
        "print(len(masked_idioms_vnc_train_not_present))\n",
        "print(len(masked_contexts_vnc_train_not_present))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "893\n",
            "893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qAnrcKvoIDL",
        "outputId": "f9b8381b-cac8-44bf-9cfb-2ab83d3af1cb"
      },
      "source": [
        "embedded_idioms_vnc_train_not_present = use_batches(padded_idioms_vnc_train_not_present, masked_idioms_vnc_train_not_present)\n",
        "len(embedded_idioms_vnc_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 693\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 493\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 293\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 93\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWDU4ocUoLWP",
        "outputId": "c9a31903-9040-4272-fd52-cd1723a76c79"
      },
      "source": [
        "embedded_contexts_vnc_train_not_present = use_batches(padded_contexts_vnc_train_not_present, masked_contexts_vnc_train_not_present)\n",
        "len(embedded_contexts_vnc_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 693\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 493\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 293\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 93\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwSGzLy5pjIr"
      },
      "source": [
        "labels_vnc_train_not_present = to_categorical(data_vnc_train.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E259-ehzq74g",
        "outputId": "fcdc28e2-291b-4c49-a972-107c5d9b8121"
      },
      "source": [
        "tokenized_idioms_vnc_test_not_present = data_vnc_test['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_vnc_test_not_present = data_vnc_test['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_vnc_test_not_present = max([len(sen) for sen in tokenized_idioms_vnc_test_not_present])\n",
        "max_context_length_vnc_test_not_present = max([len(sen) for sen in tokenized_contexts_vnc_test_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_vnc_test_not_present)\n",
        "print('Max context length: ', max_context_length_vnc_test_not_present)\n",
        "\n",
        "padded_idioms_vnc_test_not_present = pad_sentence(tokenized_idioms_vnc_test_not_present, max_idiom_length_vnc_test_not_present+5)\n",
        "padded_contexts_vnc_test_not_present = pad_sentence(tokenized_contexts_vnc_test_not_present, max_context_length_vnc_test_not_present+20)\n",
        "print(len(padded_idioms_vnc_test_not_present))\n",
        "print(len(padded_contexts_vnc_test_not_present))\n",
        "\n",
        "masked_idioms_vnc_test_not_present = create_att_masks(padded_idioms_vnc_test_not_present)\n",
        "masked_contexts_vnc_test_not_present = create_att_masks(padded_contexts_vnc_test_not_present)\n",
        "print(len(masked_idioms_vnc_test_not_present))\n",
        "print(len(masked_contexts_vnc_test_not_present))\n",
        "\n",
        "embedded_idioms_vnc_test_not_present = use_batches(padded_idioms_vnc_test_not_present, masked_idioms_vnc_test_not_present)\n",
        "len(embedded_idioms_vnc_test_not_present)\n",
        "\n",
        "embedded_contexts_vnc_test_not_present = use_batches(padded_contexts_vnc_test_not_present, masked_contexts_vnc_test_not_present)\n",
        "len(embedded_contexts_vnc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  10\n",
            "Max context length:  170\n",
            "\n",
            "Padding/truncating all sentences to 15 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 190 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "186\n",
            "186\n",
            "186\n",
            "186\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -14\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLCD8tRut7pf"
      },
      "source": [
        "labels_vnc_test_not_present = to_categorical(data_vnc_test.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNiZNWvfomcL"
      },
      "source": [
        "### ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6ZFvgZxuavk",
        "outputId": "1ea08efe-2019-49c2-a4ea-bc16f1cdfc5b"
      },
      "source": [
        "tokenized_idioms_anc_train_not_present = data_anc_train['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_anc_train_not_present = data_anc_train['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_anc_train_not_present = max([len(sen) for sen in tokenized_idioms_anc_train_not_present])\n",
        "max_context_length_anc_train_not_present = max([len(sen) for sen in tokenized_contexts_anc_train_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_anc_train_not_present)\n",
        "print('Max context length: ', max_context_length_anc_train_not_present)\n",
        "\n",
        "padded_idioms_anc_train_not_present = pad_sentence(tokenized_idioms_anc_train_not_present, max_idiom_length_anc_train_not_present+5)\n",
        "padded_contexts_anc_train_not_present = pad_sentence(tokenized_contexts_anc_train_not_present, max_context_length_anc_train_not_present+20)\n",
        "print(len(padded_idioms_anc_train_not_present))\n",
        "print(len(padded_contexts_anc_train_not_present))\n",
        "\n",
        "masked_idioms_anc_train_not_present = create_att_masks(padded_idioms_anc_train_not_present)\n",
        "masked_contexts_anc_train_not_present = create_att_masks(padded_contexts_anc_train_not_present)\n",
        "print(len(masked_idioms_anc_train_not_present))\n",
        "print(len(masked_contexts_anc_train_not_present))\n",
        "\n",
        "embedded_idioms_anc_train_not_present = use_batches(padded_idioms_anc_train_not_present, masked_idioms_anc_train_not_present)\n",
        "len(embedded_idioms_anc_train_not_present)\n",
        "\n",
        "embedded_contexts_anc_train_not_present = use_batches(padded_contexts_anc_train_not_present, masked_contexts_anc_train_not_present)\n",
        "len(embedded_contexts_anc_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  10\n",
            "Max context length:  221\n",
            "\n",
            "Padding/truncating all sentences to 15 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 241 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "643\n",
            "643\n",
            "643\n",
            "643\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 443\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 243\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 43\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -157\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 443\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 243\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 43\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76_WhQxVuLzp"
      },
      "source": [
        "labels_anc_train_not_present = to_categorical(data_anc_train.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5xjyRsoubhn",
        "outputId": "bfbc3559-b821-4892-8040-a06209fe2310"
      },
      "source": [
        "tokenized_idioms_anc_test_not_present = data_anc_test['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_anc_test_not_present = data_anc_test['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_anc_test_not_present = max([len(sen) for sen in tokenized_idioms_anc_test_not_present])\n",
        "max_context_length_anc_test_not_present = max([len(sen) for sen in tokenized_contexts_anc_test_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_anc_test_not_present)\n",
        "print('Max context length: ', max_context_length_anc_test_not_present)\n",
        "\n",
        "padded_idioms_anc_test_not_present = pad_sentence(tokenized_idioms_anc_test_not_present, max_idiom_length_anc_test_not_present+5)\n",
        "padded_contexts_anc_test_not_present = pad_sentence(tokenized_contexts_anc_test_not_present, max_context_length_anc_test_not_present+20)\n",
        "print(len(padded_idioms_anc_test_not_present))\n",
        "print(len(padded_contexts_anc_test_not_present))\n",
        "\n",
        "masked_idioms_anc_test_not_present = create_att_masks(padded_idioms_anc_test_not_present)\n",
        "masked_contexts_anc_test_not_present = create_att_masks(padded_contexts_anc_test_not_present)\n",
        "print(len(masked_idioms_anc_test_not_present))\n",
        "print(len(masked_contexts_anc_test_not_present))\n",
        "\n",
        "embedded_idioms_anc_test_not_present = use_batches(padded_idioms_anc_test_not_present, masked_idioms_anc_test_not_present)\n",
        "len(embedded_idioms_anc_test_not_present)\n",
        "\n",
        "embedded_contexts_anc_test_not_present = use_batches(padded_contexts_anc_test_not_present, masked_contexts_anc_test_not_present)\n",
        "len(embedded_contexts_anc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  192\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 212 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "163\n",
            "163\n",
            "163\n",
            "163\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -37\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XPmQUstuItS"
      },
      "source": [
        "labels_anc_test_not_present = to_categorical(data_anc_test.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGR3h9qZe_dw"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_WQ4PatxO4Y"
      },
      "source": [
        "### VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbu5n0Rhe5KJ",
        "outputId": "ebdbd7e8-a622-4518-8215-46f94d8c1ce1"
      },
      "source": [
        "model_vnc_not_present = Sequential()\n",
        "model_vnc_not_present.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_vnc_not_present.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_vnc_not_present.add(Dense(NUM_CLASSES))\n",
        "model_vnc_not_present.add(Activation('softmax'))\n",
        "\n",
        "model_vnc_not_present.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wlXodaUfQp3",
        "outputId": "41fb6475-3302-403d-f7a8-fdc3d9a112bb"
      },
      "source": [
        "model_vnc_not_present.fit(np.asarray(embedded_contexts_vnc_train_not_present), \n",
        "              labels_vnc_train_not_present, batch_size=8, epochs=10)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_4_input'), name='masking_4_input', description=\"created by layer 'masking_4_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_4_input'), name='masking_4_input', description=\"created by layer 'masking_4_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "112/112 [==============================] - 31s 217ms/step - loss: 0.6337 - accuracy: 0.6310\n",
            "Epoch 2/10\n",
            "112/112 [==============================] - 24s 218ms/step - loss: 0.4378 - accuracy: 0.8046\n",
            "Epoch 3/10\n",
            "112/112 [==============================] - 24s 217ms/step - loss: 0.4091 - accuracy: 0.8113\n",
            "Epoch 4/10\n",
            "112/112 [==============================] - 24s 218ms/step - loss: 0.3226 - accuracy: 0.8720\n",
            "Epoch 5/10\n",
            "112/112 [==============================] - 24s 217ms/step - loss: 0.3061 - accuracy: 0.8759\n",
            "Epoch 6/10\n",
            "112/112 [==============================] - 24s 216ms/step - loss: 0.2552 - accuracy: 0.8789\n",
            "Epoch 7/10\n",
            "112/112 [==============================] - 24s 215ms/step - loss: 0.2190 - accuracy: 0.9226\n",
            "Epoch 8/10\n",
            "112/112 [==============================] - 24s 216ms/step - loss: 0.1852 - accuracy: 0.9244\n",
            "Epoch 9/10\n",
            "112/112 [==============================] - 24s 216ms/step - loss: 0.1465 - accuracy: 0.9529\n",
            "Epoch 10/10\n",
            "112/112 [==============================] - 24s 217ms/step - loss: 0.1259 - accuracy: 0.9463\n",
            "fit model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVU6PZjdyaCS",
        "outputId": "5548fcb8-b42c-484a-9bed-1afd5d48d0f8"
      },
      "source": [
        "model_vnc_not_present.evaluate(np.asarray(embedded_contexts_vnc_test_not_present), labels_vnc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_4_input'), name='masking_4_input', description=\"created by layer 'masking_4_input'\"), but it was called on an input with incompatible shape (None, 190, 768).\n",
            "6/6 [==============================] - 3s 72ms/step - loss: 0.1252 - accuracy: 0.9570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12515968084335327, 0.9569892287254333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaPXmKF9ypUW",
        "outputId": "f68fb69f-f6ba-4c4c-d3f8-9855606a26eb"
      },
      "source": [
        "preds_vnc_not_present = model_vnc_not_present.predict(np.array(embedded_contexts_vnc_test_not_present))\n",
        "f1_score(np.argmax(preds_vnc_not_present, axis=1), np.argmax(labels_vnc_test_not_present, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.943661971830986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55pgDltfxRV7"
      },
      "source": [
        "### ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzIKtWSPy-Ml",
        "outputId": "50709acd-2148-4adc-a4dd-8fc6b9faa745"
      },
      "source": [
        "model_anc_not_present = Sequential()\n",
        "model_anc_not_present.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_anc_not_present.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_anc_not_present.add(Dense(NUM_CLASSES))\n",
        "model_anc_not_present.add(Activation('softmax'))\n",
        "\n",
        "model_anc_not_present.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k8_IQK0zIht",
        "outputId": "f0bcd097-0091-411d-f2c6-666eda553110"
      },
      "source": [
        "model_anc_not_present.fit(np.asarray(embedded_contexts_anc_train_not_present), \n",
        "              labels_anc_train_not_present, batch_size=8, epochs=10)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "81/81 [==============================] - 23s 205ms/step - loss: 0.6829 - accuracy: 0.5610\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.5093 - accuracy: 0.7728\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.4509 - accuracy: 0.8079\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.4196 - accuracy: 0.8005\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.3624 - accuracy: 0.8470\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.3158 - accuracy: 0.8774\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.2712 - accuracy: 0.9077\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.2395 - accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.1902 - accuracy: 0.9419\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 17s 206ms/step - loss: 0.1378 - accuracy: 0.9536\n",
            "fit model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF0DpzSMzO0_",
        "outputId": "8f273cc6-d41b-443d-fa1a-0b62d5bd179d"
      },
      "source": [
        "model_anc_not_present.evaluate(np.asarray(embedded_contexts_anc_test_not_present), labels_anc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 212, 768).\n",
            "6/6 [==============================] - 3s 69ms/step - loss: 1.2682 - accuracy: 0.5644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2682161331176758, 0.5644171833992004]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGXhVdh_zcvw",
        "outputId": "8b351625-ea61-4e0e-a11e-a5f56e816ea7"
      },
      "source": [
        "preds_anc_not_present = model_anc_not_present.predict(np.array(embedded_contexts_anc_test_not_present))\n",
        "f1_score(np.argmax(preds_anc_not_present, axis=1), np.argmax(labels_anc_test_not_present, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 212, 768).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6077348066298343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    }
  ]
}