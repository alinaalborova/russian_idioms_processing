{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31/5 MICE - fastText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQJbDyrs6ZrvP+03OBFxoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinaalborova/russian_idioms_processing/blob/main/MICE_fastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n5x1wCqtCTH"
      },
      "source": [
        "# Idiom Type and Token Classification\n",
        "\n",
        "Based on [MICE: Mining Idioms with Contextual Embeddings](https://arxiv.org/pdf/2008.05759.pdf) by  Škvorc et al.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIpMYL-jCvaf",
        "outputId": "99329717-0e02-4ca9-9c9c-f1f5e7559314"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensor2tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Collecting tensor2tensor\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/7c/9e87d30cefad5cbc390bb7f626efb3ded9b19416b8160f1a1278da81b218/tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.16.0)\n",
            "Collecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dopamine-rl in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.0.5)\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.12.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (7.1.2)\n",
            "Collecting tensorflow-gan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.19.5)\n",
            "Collecting mesh-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/10/37df0bc87ebf84e1414613176340e3aadc3697d2bd112bf63d3d4b1e848a/mesh_tensorflow-0.1.19-py3-none-any.whl (366kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.4.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (3.1.0)\n",
            "Collecting kfac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/36/06fe2c757044bb51906fef231ac48cc5bf9a277fc9a8c7e1108d7e9e8cfd/kfac-0.2.3-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (2.23.0)\n",
            "Collecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.2.30)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.15.0)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 27.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 36.0MB/s \n",
            "\u001b[?25hCollecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 27.9MB/s \n",
            "\u001b[?25hCollecting bz2file\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.12.8)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.0.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.41.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->tensor2tensor) (1.2.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (4.4.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gan->tensor2tensor) (0.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor) (1.5.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->tensor2tensor) (1.5.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2.10)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->tensor2tensor) (56.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tensor2tensor) (2.7.1)\n",
            "Collecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.26.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.30.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (3.0.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.2.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.0.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.1.6)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (5.1.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (21.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (3.12.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.3.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (1.0.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (1.53.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client->tensor2tensor) (4.2.2)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tensor2tensor) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->tensor2tensor) (2.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (2.4.7)\n",
            "Building wheels for collected packages: pypng, bz2file\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp37-none-any.whl size=67163 sha256=dab200541f1199f8a657303d4689ef9119a07f64e98de14b95c973a68fb18515\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-cp37-none-any.whl size=6884 sha256=931e5b261883ccd23714ae164e61e8ed262d9fde00e3f1e817307b8d26843f38\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built pypng bz2file\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pypng, tensorflow-probability, tensorflow-gan, mesh-tensorflow, kfac, gunicorn, tf-slim, tensorflow-addons, zope.event, zope.interface, gevent, bz2file, tensor2tensor\n",
            "  Found existing installation: tensorflow-probability 0.12.1\n",
            "    Uninstalling tensorflow-probability-0.12.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.12.1\n",
            "Successfully installed bz2file-0.98 gevent-21.1.2 gunicorn-20.1.0 kfac-0.2.3 mesh-tensorflow-0.1.19 pypng-0.0.20 tensor2tensor-1.15.7 tensorflow-addons-0.13.0 tensorflow-gan-2.0.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45kdfZ-cCyBf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import tensorflow as tf\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ9ZuPImB9fu"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Activation, TimeDistributed, Masking, GRU\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx37LYuVm2FV"
      },
      "source": [
        "## Install & Import fastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PloLd8nBm5WG",
        "outputId": "dc01af8a-7bdf-4f90-f893-d9b42c0d592b"
      },
      "source": [
        "pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (56.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3098404 sha256=8f73f118b52ba2039ff7f23613112ddddb049c9ca0bcb4a91f4a3bdc8111abff\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoQYxB3PnGdy",
        "outputId": "8b6a0a5c-0124-4236-9172-95635bbeca92"
      },
      "source": [
        "import fasttext.util\n",
        "fasttext.util.download_model('ru', if_exists='ignore')  # Russian\n",
        "ft = fasttext.load_model('cc.ru.300.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ07_hgeCG7N"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGdFYdryCFnx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "p_LXZJEgCP1I",
        "outputId": "4e2895c3-485f-4f68-8bf6-9836e095eb3d"
      },
      "source": [
        "dataset_vnc_dir = '/content/drive/MyDrive/ВКР/Sense Disambiguation Corpus/VNCs_Annotated.csv'\n",
        "data_vnc = pd.read_csv(dataset_vnc_dir )\n",
        "data_vnc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                            Example\n",
              "0   бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1   бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWbTSEvZcBFR",
        "outputId": "42718504-bbbd-455a-c031-763c49d987fc"
      },
      "source": [
        "data_vnc.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    455\n",
              "0    438\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX3x1pJbvQB_",
        "outputId": "74e69fbf-3571-476c-cd8e-fd4d3ed9686d"
      },
      "source": [
        "data_vnc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUS3mxovE9b",
        "outputId": "74d8f239-8e38-4421-f901-8d5d3d0dc987"
      },
      "source": [
        "len(data_vnc['Idiom Normal'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "1__zN0o2bMHa",
        "outputId": "3507bdfa-0168-4731-9abf-76463c145bd8"
      },
      "source": [
        "dataset_anc_dir = '/content/drive/MyDrive/ВКР/Sense Disambiguation Corpus/ANCs_Annotated.csv'\n",
        "data_anc = pd.read_csv(dataset_anc_dir )\n",
        "data_anc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>0</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>0</td>\n",
              "      <td>Как почтовый возок на избитой дороге, прыгает...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Idiom Normal  ...                                            Example\n",
              "0  избитая дорога  ...   С бурной быстротой, возможной только в сновид...\n",
              "1  избитая дорога  ...   Как почтовый возок на избитой дороге, прыгает...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-TI7acRTEtJ",
        "outputId": "6d2b1ad5-bace-498a-b454-a480370596ca"
      },
      "source": [
        "len(data_anc['Idiom Inflected'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBToZl7vtLeo",
        "outputId": "4e593b23-8d90-41cc-9813-d393de0b04a8"
      },
      "source": [
        "data_anc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "больное место                 57\n",
              "правая рука                   56\n",
              "болевая точка                 52\n",
              "нож острый                    49\n",
              "путеводная звезда             48\n",
              "лавровый венок                44\n",
              "бедный родственник            41\n",
              "тяжёлая рука                  38\n",
              "зелёная улица                 38\n",
              "ваш брат                      34\n",
              "вавилонское столпотворение    30\n",
              "наша сестра                   28\n",
              "пороховая бочка               27\n",
              "дальний прицел                25\n",
              "вторая ступень                23\n",
              "заблудшая овца                23\n",
              "старый воробей                22\n",
              "красная бумажка               21\n",
              "синяя птица                   20\n",
              "долгая песня                  18\n",
              "другой разговор               18\n",
              "старый гриб                   16\n",
              "чёрная кость                  15\n",
              "девичья кожа                  12\n",
              "маковое зерно                 10\n",
              "музейная редкость             10\n",
              "избитая дорога                10\n",
              "ободранная кошка               9\n",
              "куриная голова                 9\n",
              "чернильная строка              3\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gLTJiitUym",
        "outputId": "b6735dad-44ee-4efd-af90-8ba5904341c3"
      },
      "source": [
        "len(data_anc['Idiom Normal'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "6kSMItV0er4B",
        "outputId": "7c3a1c7a-0a03-4e40-84a9-e9c73cddd697"
      },
      "source": [
        "data = pd.concat([data_vnc, data_anc], ignore_index=True)\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                            Example\n",
              "0   бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1   бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qwnf70b0jr",
        "outputId": "d370cb95-a787-4c13-b234-30d5ef7b456e"
      },
      "source": [
        "data['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    856\n",
              "1    843\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G5ZVn4qqSbB",
        "outputId": "009b9573-83f7-4e9d-dda0-37b3c2514480"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1699, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "RTjCivomgQsz",
        "outputId": "cf214256-2c2d-49e2-d26b-078aa43f3356"
      },
      "source": [
        "data.tail(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1697</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедными родственниками</td>\n",
              "      <td>0</td>\n",
              "      <td>Проходя мимо церквей, я вижу иногда человека,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1698</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедных родственниках</td>\n",
              "      <td>0</td>\n",
              "      <td>[Егор Дмитрич Глумов, муж]   У молодой женщин...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Idiom Normal  ...                                            Example\n",
              "1697  бедный родственник  ...   Проходя мимо церквей, я вижу иногда человека,...\n",
              "1698  бедный родственник  ...   [Егор Дмитрич Глумов, муж]   У молодой женщин...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ37N3KIgXiK",
        "outputId": "528c78c3-7a41-4e2d-b581-c65fcbb1701b"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1699, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBdk00Dfo7zD"
      },
      "source": [
        "## Tokenize & Get fastText Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4ohX1k2CneW"
      },
      "source": [
        "import re\n",
        "GROUPING_SPACE_REGEX = re.compile('([^\\w_-]|[+])', re.U)\n",
        "\n",
        "def tokenize(text):\n",
        "  \"\"\"\n",
        "  Split text into tokens. Don't split by hyphen.\n",
        "  \"\"\"\n",
        "  return [t for t in GROUPING_SPACE_REGEX.split(text)\n",
        "          if t and not t.isspace()]\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def pad_sentence(tokenized, max_len):\n",
        "  print('\\nPadding/truncating all sentences to %d values...' % max_len)\n",
        "  print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "  # Pad our input tokens with value 0.\n",
        "  # \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "  # as opposed to the beginning.\n",
        "  input_ids = pad_sequences(tokenized, maxlen=max_len, dtype=\"long\", \n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "  print('\\nDone.')\n",
        "  return input_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJYwMhtIytmQ"
      },
      "source": [
        "def get_embeddings(text, length, padded_size=100):\n",
        "  vec_size = 300\n",
        "  embeddings_list = []\n",
        "  for i, sentence in enumerate(text):\n",
        "    local_embeddings = np.empty(shape=(padded_size, ), dtype=object)\n",
        "    for id, token in enumerate(local_embeddings):\n",
        "      try:\n",
        "        local_embeddings[id] = ft.get_word_vector(sentence[id])\n",
        "      except:\n",
        "        local_embeddings[id] = np.zeros(vec_size)\n",
        "    embeddings_list.append(local_embeddings)\n",
        "  return embeddings_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKsrUNqro3EN"
      },
      "source": [
        "### All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uOnk2W6gpod"
      },
      "source": [
        "contexts_tokenized_all = data.Example.apply(tokenize)\n",
        "embedded_contexts_all = get_embeddings(contexts_tokenized_all, length=len(list(contexts_tokenized_all)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sC1iDgaqqY3"
      },
      "source": [
        "labels = to_categorical(data.Label)\n",
        "X_train, X_test = train_test_split(embedded_contexts_all, test_size=0.2)\n",
        "Y_train, Y_test = train_test_split(labels, test_size=0.2)\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "X_test = tf.convert_to_tensor(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZvVEcpBpBpT"
      },
      "source": [
        "### VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJU7934Ao6wE"
      },
      "source": [
        "contexts_tokenized_vnc = data_vnc.Example.apply(tokenize)\n",
        "embedded_contexts_vnc = get_embeddings(contexts_tokenized_vnc, length=len(list(contexts_tokenized_vnc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn2XXmEuqY_n"
      },
      "source": [
        "labels_vnc = to_categorical(data_vnc.Label)\n",
        "X_train_vnc, X_test_vnc = train_test_split(embedded_contexts_vnc, test_size=0.2)\n",
        "Y_train_vnc, Y_test_vnc = train_test_split(labels_vnc, test_size=0.2)\n",
        "X_train_vnc = tf.convert_to_tensor(X_train_vnc)\n",
        "X_test_vnc = tf.convert_to_tensor(X_test_vnc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gfv0JQTpLF0"
      },
      "source": [
        "### ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPNum48TpM81"
      },
      "source": [
        "contexts_tokenized_anc = data_anc.Example.apply(tokenize)\n",
        "embedded_contexts_anc = get_embeddings(contexts_tokenized_anc, length=len(list(contexts_tokenized_anc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGQCIkqmrCrd"
      },
      "source": [
        "labels_anc = to_categorical(data_anc.Label)\n",
        "X_train_anc, X_test_anc = train_test_split(embedded_contexts_anc, test_size=0.2)\n",
        "Y_train_anc, Y_test_anc = train_test_split(labels_anc, test_size=0.2)\n",
        "X_train_anc = tf.convert_to_tensor(X_train_anc)\n",
        "X_test_anc = tf.convert_to_tensor(X_test_anc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhEfUvMDCJiH"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4_lb8Xr-0jW"
      },
      "source": [
        "MAX_SEQUENCE_LEN = 500\n",
        "VECTOR_DIM = 300\n",
        "NUM_CLASSES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaIqYgQ00xcG"
      },
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "  forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "  backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                      go_backwards=True)\n",
        "  model.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                        input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "  model.add(Dense(NUM_CLASSES))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "  print('compiled model')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt7bOMjP6KKU"
      },
      "source": [
        "### All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-geAYheaEgWb",
        "outputId": "1c2a9e53-a45e-48d8-b5f8-3082746964a1"
      },
      "source": [
        "model_all = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshn2ysyGgvg",
        "outputId": "ce116a67-eb80-4896-9b48-22800a9cf66f"
      },
      "source": [
        "model_all = build_model()\n",
        "model_all.fit(X_train, Y_train, batch_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "170/170 [==============================] - 23s 92ms/step - loss: 0.6952 - accuracy: 0.5173\n",
            "Epoch 2/10\n",
            "170/170 [==============================] - 16s 92ms/step - loss: 0.6917 - accuracy: 0.5202\n",
            "Epoch 3/10\n",
            "170/170 [==============================] - 16s 92ms/step - loss: 0.6874 - accuracy: 0.5423\n",
            "Epoch 4/10\n",
            "170/170 [==============================] - 15s 91ms/step - loss: 0.6862 - accuracy: 0.5570\n",
            "Epoch 5/10\n",
            "170/170 [==============================] - 16s 92ms/step - loss: 0.6805 - accuracy: 0.5681\n",
            "Epoch 6/10\n",
            "170/170 [==============================] - 16s 93ms/step - loss: 0.6720 - accuracy: 0.6026\n",
            "Epoch 7/10\n",
            "170/170 [==============================] - 15s 91ms/step - loss: 0.6743 - accuracy: 0.5651\n",
            "Epoch 8/10\n",
            "170/170 [==============================] - 15s 91ms/step - loss: 0.6668 - accuracy: 0.5857\n",
            "Epoch 9/10\n",
            "170/170 [==============================] - 16s 92ms/step - loss: 0.6603 - accuracy: 0.6115\n",
            "Epoch 10/10\n",
            "170/170 [==============================] - 16s 91ms/step - loss: 0.6477 - accuracy: 0.6284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f870d945d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT389s3HGsqB",
        "outputId": "08508087-d110-4db6-c6d8-a0bcf8b8a44a"
      },
      "source": [
        "model_all.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "11/11 [==============================] - 3s 29ms/step - loss: 0.7097 - accuracy: 0.4706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7096795439720154, 0.47058823704719543]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Vhn0Gd6TpJ",
        "outputId": "e0fd35cf-49cc-42e3-b96c-5dbc4492051f"
      },
      "source": [
        "preds_all = model_all.predict(np.asarray(X_test))\n",
        "f1_score(np.argmax(preds_all, axis=1), np.argmax(Y_test, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5027624309392265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s180MJn0jcj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Qtz4jxj685"
      },
      "source": [
        "### VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzhB5L6gnPPm",
        "outputId": "59bee7fd-5ff9-484d-c8b2-280c62e1be85"
      },
      "source": [
        "model_vnc = build_model()\n",
        "model_vnc.fit(X_train_vnc, Y_train_vnc, batch_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "90/90 [==============================] - 15s 91ms/step - loss: 0.6948 - accuracy: 0.5154\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 8s 91ms/step - loss: 0.6886 - accuracy: 0.5378\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 8s 91ms/step - loss: 0.6822 - accuracy: 0.5588\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 8s 90ms/step - loss: 0.6777 - accuracy: 0.5826\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 8s 93ms/step - loss: 0.6735 - accuracy: 0.6022\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 8s 91ms/step - loss: 0.6551 - accuracy: 0.6303\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 8s 92ms/step - loss: 0.6503 - accuracy: 0.6499\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 8s 92ms/step - loss: 0.6441 - accuracy: 0.6317\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 8s 90ms/step - loss: 0.6329 - accuracy: 0.6429\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 8s 90ms/step - loss: 0.6173 - accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f87089e7310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bZm3Lv3rFfn",
        "outputId": "7002e86f-3a65-4bb1-f978-32f7cfd62bf0"
      },
      "source": [
        "model_vnc.evaluate(X_test_vnc, Y_test_vnc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "6/6 [==============================] - 2s 29ms/step - loss: 0.7380 - accuracy: 0.4860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7380333542823792, 0.48603352904319763]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoDI93oksnTb",
        "outputId": "a09bb775-5ded-4f5b-f78e-4e7c15fa0af6"
      },
      "source": [
        "preds_vnc = model_vnc.predict(np.array(X_test_vnc))\n",
        "f1_score(np.argmax(preds_vnc, axis=1), np.argmax(Y_test_vnc, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5533980582524272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABSFxZNrNz0"
      },
      "source": [
        "### ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe2LfJxJs2Z6",
        "outputId": "5c1c6559-c125-4998-b800-ccab023fe8ba"
      },
      "source": [
        "model_anc = build_model()\n",
        "model_anc.fit(X_train_anc, Y_train_anc, batch_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_3_input'), name='masking_3_input', description=\"created by layer 'masking_3_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_3_input'), name='masking_3_input', description=\"created by layer 'masking_3_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "81/81 [==============================] - 14s 91ms/step - loss: 0.6981 - accuracy: 0.4984\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 8s 93ms/step - loss: 0.6895 - accuracy: 0.5435\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 7s 91ms/step - loss: 0.6846 - accuracy: 0.5466\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 8s 94ms/step - loss: 0.6805 - accuracy: 0.5652\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 7s 91ms/step - loss: 0.6767 - accuracy: 0.5854\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 7s 91ms/step - loss: 0.6681 - accuracy: 0.6071\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 7s 90ms/step - loss: 0.6599 - accuracy: 0.6304\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 8s 93ms/step - loss: 0.6564 - accuracy: 0.6118\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 7s 93ms/step - loss: 0.6444 - accuracy: 0.6568\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 8s 94ms/step - loss: 0.6351 - accuracy: 0.6724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f870540ef90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6txZ7eLitC1R",
        "outputId": "c29825ec-6851-4ffb-936f-735ae850396b"
      },
      "source": [
        "model_anc.evaluate(X_test_anc, Y_test_anc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_3_input'), name='masking_3_input', description=\"created by layer 'masking_3_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n",
            "6/6 [==============================] - 3s 25ms/step - loss: 0.6913 - accuracy: 0.5309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6913085579872131, 0.5308641791343689]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh-5CfhwstLC",
        "outputId": "8d909eb1-20f9-466c-d3fc-70c9ff50b922"
      },
      "source": [
        "preds_anc = model_anc.predict(X_test_anc)\n",
        "f1_score(np.argmax(preds_anc, axis=1), np.argmax(Y_test_anc, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 300), dtype=tf.float32, name='masking_3_input'), name='masking_3_input', description=\"created by layer 'masking_3_input'\"), but it was called on an input with incompatible shape (None, 100, 300).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5189873417721519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}