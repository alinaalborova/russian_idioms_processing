{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of 31.05. MICE - multiBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fRBmEtbQfmZs"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOpIaEmEcKEQvZfE5y0sWpf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94d340ed7c4f4567b6a9522424cd9028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2c40cf5776c40e7bdacc42973b880a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9956555a7a1f48488821b1139ecbf526",
              "IPY_MODEL_99a7bd4a2a04499fb5bd8ef19895b9fa"
            ]
          }
        },
        "c2c40cf5776c40e7bdacc42973b880a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9956555a7a1f48488821b1139ecbf526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bffff130fc404e6eae6e609b2a159010",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dee218b1b6874f4d9ab130af11e90f21"
          }
        },
        "99a7bd4a2a04499fb5bd8ef19895b9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_192d46450bc6433287470c270b9ec9e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:01&lt;00:00, 930kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09506d1c7e274a92aadafb4632102704"
          }
        },
        "bffff130fc404e6eae6e609b2a159010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dee218b1b6874f4d9ab130af11e90f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "192d46450bc6433287470c270b9ec9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09506d1c7e274a92aadafb4632102704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c7a1869c1b04c1fa48ecda60da3b1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4f07e3f889643bdb942e710e4e8764d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d822dbd363d4bb8846d9c88920ae57a",
              "IPY_MODEL_43916718b37d4c26a6cbf26687eaad85"
            ]
          }
        },
        "c4f07e3f889643bdb942e710e4e8764d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d822dbd363d4bb8846d9c88920ae57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_146f9b9ea6e247c4abc6f0a2fdb8e08b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e09ef60f67c3485986adabe6556f2660"
          }
        },
        "43916718b37d4c26a6cbf26687eaad85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3428123910a84dfdb1702b9aa65ee717",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 54.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab848434c52144df9cef307c2bcfd4c7"
          }
        },
        "146f9b9ea6e247c4abc6f0a2fdb8e08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e09ef60f67c3485986adabe6556f2660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3428123910a84dfdb1702b9aa65ee717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab848434c52144df9cef307c2bcfd4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d03d8857dbc4320af8ed119a052db7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f00b453dc9994626888d9a3bc32d091d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6c2b5e9d39b42be8257061374f7d93d",
              "IPY_MODEL_d59a83cb56c14746aed2ba8c39382404"
            ]
          }
        },
        "f00b453dc9994626888d9a3bc32d091d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6c2b5e9d39b42be8257061374f7d93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d91341f71d704a7bb32c049ae7697368",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1961828,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1961828,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7c4b0c90c9f4935a72caa8479513faf"
          }
        },
        "d59a83cb56c14746aed2ba8c39382404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b5c94d7846048909190f0c6135b072f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 7.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dbaa8b649fd4cd091e4de1faa5b34ef"
          }
        },
        "d91341f71d704a7bb32c049ae7697368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7c4b0c90c9f4935a72caa8479513faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b5c94d7846048909190f0c6135b072f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dbaa8b649fd4cd091e4de1faa5b34ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a5ba35122b9427f8a1fd729b1f4a6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_746cd75c3dac400fbfb7e25edd0e37c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58ab95843a1d4ed7886bfbe15ed83551",
              "IPY_MODEL_6b0e96fe313a4e9a8922ee6bfc5de446"
            ]
          }
        },
        "746cd75c3dac400fbfb7e25edd0e37c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58ab95843a1d4ed7886bfbe15ed83551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a7f42a689984f0b871ce5e8f4b502e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7586034dbeb14ed99034e308e4ec867b"
          }
        },
        "6b0e96fe313a4e9a8922ee6bfc5de446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03ef94f8eaa8491d910542a36280589a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 874B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99f4996a7fcf492ca765fca643a49e57"
          }
        },
        "0a7f42a689984f0b871ce5e8f4b502e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7586034dbeb14ed99034e308e4ec867b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ef94f8eaa8491d910542a36280589a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99f4996a7fcf492ca765fca643a49e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b4fa0fce91e4763939e8e59e93f1804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83165302c61a4cb09375e91c5ec79d12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8ffc9d7197d4215bb1b17f8b364d46e",
              "IPY_MODEL_b9c2f6827a2140419d1154b5053f029f"
            ]
          }
        },
        "83165302c61a4cb09375e91c5ec79d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8ffc9d7197d4215bb1b17f8b364d46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_951f3f8db2804f1fb36fab3e41dce537",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1083389348,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1083389348,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f00209be668d4e7fb464b9d960b4c7fe"
          }
        },
        "b9c2f6827a2140419d1154b5053f029f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b75ca59b5dcb4a9f979082acd625c0ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08G/1.08G [00:26&lt;00:00, 41.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_475fa0e02ac74227b2e02190785152be"
          }
        },
        "951f3f8db2804f1fb36fab3e41dce537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f00209be668d4e7fb464b9d960b4c7fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b75ca59b5dcb4a9f979082acd625c0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "475fa0e02ac74227b2e02190785152be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinaalborova/russian_idioms_processing/blob/main/MICE_multiBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n5x1wCqtCTH"
      },
      "source": [
        "# Idiom Type and Token Classification\n",
        "\n",
        "Based on [MICE: Mining Idioms with Contextual Embeddings](https://arxiv.org/pdf/2008.05759.pdf) by  Škvorc et al.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIpMYL-jCvaf",
        "outputId": "0baeba26-613c-4b3c-a111-88c803929d6f"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensor2tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 39.4MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Collecting tensor2tensor\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/7c/9e87d30cefad5cbc390bb7f626efb3ded9b19416b8160f1a1278da81b218/tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.7.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.4.0)\n",
            "Collecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 33.3MB/s \n",
            "\u001b[?25hCollecting bz2file\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: dopamine-rl in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (2.23.0)\n",
            "Collecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.1.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (7.1.2)\n",
            "Collecting kfac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/36/06fe2c757044bb51906fef231ac48cc5bf9a277fc9a8c7e1108d7e9e8cfd/kfac-0.2.3-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.19.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.16.0)\n",
            "Collecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/dd/5b190393e6066286773a67dfcc2f9492058e9b57c4867a95f1ba5caf0a83/gunicorn-20.1.0-py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.0.1)\n",
            "Collecting mesh-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/10/37df0bc87ebf84e1414613176340e3aadc3697d2bd112bf63d3d4b1e848a/mesh_tensorflow-0.1.19-py3-none-any.whl (366kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (1.12.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (0.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from tensor2tensor) (4.1.2.30)\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 44.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 42.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-gan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 25.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->tensor2tensor) (1.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor) (3.0.4)\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 39.7MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent->tensor2tensor) (56.1.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->tensor2tensor) (1.5.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (3.12.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (21.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.0.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (5.1.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor) (0.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor) (4.7.2)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.30.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor) (0.0.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor) (4.4.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tensor2tensor) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gan->tensor2tensor) (0.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->tensor2tensor) (2.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tensor2tensor) (1.53.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tensor2tensor) (3.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client->tensor2tensor) (4.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor) (2.4.7)\n",
            "Building wheels for collected packages: pypng, bz2file\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp37-none-any.whl size=67163 sha256=8db9423431ddf80297b32b8417cb394e132140c084e50b5317a133b45b4f0eab\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-cp37-none-any.whl size=6884 sha256=21ab8cbdfe8c93e1a126a800e5944e71abda1aca855b49675b640ce22a0b8e1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built pypng bz2file\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pypng, bz2file, zope.interface, zope.event, gevent, tensorflow-probability, kfac, tf-slim, gunicorn, mesh-tensorflow, tensorflow-addons, tensorflow-gan, tensor2tensor\n",
            "  Found existing installation: tensorflow-probability 0.12.1\n",
            "    Uninstalling tensorflow-probability-0.12.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.12.1\n",
            "Successfully installed bz2file-0.98 gevent-21.1.2 gunicorn-20.1.0 kfac-0.2.3 mesh-tensorflow-0.1.19 pypng-0.0.20 tensor2tensor-1.15.7 tensorflow-addons-0.13.0 tensorflow-gan-2.0.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45kdfZ-cCyBf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import tensorflow as tf\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ9ZuPImB9fu"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Activation, TimeDistributed, Masking, GRU\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from ast import literal_eval\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ07_hgeCG7N"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGdFYdryCFnx",
        "outputId": "e276d6a9-e7d4-44c4-a272-4b965d4ab0cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "p_LXZJEgCP1I",
        "outputId": "89ddeb27-5135-445b-b909-981e4a820a98"
      },
      "source": [
        "dataset_vnc_dir = '/content/drive/MyDrive/ВКР/Sense Disambiguation Corpus/VNCs_Annotated.csv'\n",
        "data_vnc = pd.read_csv(dataset_vnc_dir )\n",
        "data_vnc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                            Example\n",
              "0   бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1   бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWbTSEvZcBFR",
        "outputId": "32f5426d-e860-49ea-c89f-5bfe43b69e17"
      },
      "source": [
        "data_vnc.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    455\n",
              "0    438\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX3x1pJbvQB_",
        "outputId": "74e69fbf-3571-476c-cd8e-fd4d3ed9686d"
      },
      "source": [
        "data_vnc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUS3mxovE9b",
        "outputId": "7ac8b27d-d200-463c-93c9-7f72f2f62cba"
      },
      "source": [
        "len(data_vnc['Idiom Normal'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-TI7acRTEtJ",
        "outputId": "9f2086f6-7921-4401-add2-650ccefdda41"
      },
      "source": [
        "len(data_anc['Idiom Inflected'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "1__zN0o2bMHa",
        "outputId": "3ea5af66-1229-47d6-d825-9541f55d5c23"
      },
      "source": [
        "dataset_anc_dir = '/content/drive/MyDrive/ВКР/Sense Disambiguation Corpus/ANCs_Annotated.csv'\n",
        "data_anc = pd.read_csv(dataset_anc_dir )\n",
        "data_anc.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>0</td>\n",
              "      <td>С бурной быстротой, возможной только в сновид...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>избитая дорога</td>\n",
              "      <td>избитой дороге</td>\n",
              "      <td>0</td>\n",
              "      <td>Как почтовый возок на избитой дороге, прыгает...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Idiom Normal  ...                                            Example\n",
              "0  избитая дорога  ...   С бурной быстротой, возможной только в сновид...\n",
              "1  избитая дорога  ...   Как почтовый возок на избитой дороге, прыгает...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBToZl7vtLeo",
        "outputId": "ce4083ea-5a99-4380-97fa-7b130b7a2c1d"
      },
      "source": [
        "data_anc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "больное место                 57\n",
              "правая рука                   56\n",
              "болевая точка                 52\n",
              "нож острый                    49\n",
              "путеводная звезда             48\n",
              "лавровый венок                44\n",
              "бедный родственник            41\n",
              "зелёная улица                 38\n",
              "тяжёлая рука                  38\n",
              "ваш брат                      34\n",
              "вавилонское столпотворение    30\n",
              "наша сестра                   28\n",
              "пороховая бочка               27\n",
              "дальний прицел                25\n",
              "вторая ступень                23\n",
              "заблудшая овца                23\n",
              "старый воробей                22\n",
              "красная бумажка               21\n",
              "синяя птица                   20\n",
              "другой разговор               18\n",
              "долгая песня                  18\n",
              "старый гриб                   16\n",
              "чёрная кость                  15\n",
              "девичья кожа                  12\n",
              "маковое зерно                 10\n",
              "избитая дорога                10\n",
              "музейная редкость             10\n",
              "куриная голова                 9\n",
              "ободранная кошка               9\n",
              "чернильная строка              3\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gLTJiitUym",
        "outputId": "75b56fdd-b021-4714-e91b-2884a362720e"
      },
      "source": [
        "len(data_anc['Idiom Normal'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qwnf70b0jr",
        "outputId": "8303be46-38ea-4031-e67e-0c3224b46957"
      },
      "source": [
        "data['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    856\n",
              "1    843\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G5ZVn4qqSbB",
        "outputId": "2d513345-f7c5-441a-fda6-0cc6f1375042"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1699, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "6kSMItV0er4B",
        "outputId": "cca3b8ce-fba8-4483-cbc5-8cb0e14cc93a"
      },
      "source": [
        "data = pd.concat([data_vnc, data_anc], ignore_index=True)\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                            Example\n",
              "0   бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1   бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "RTjCivomgQsz",
        "outputId": "5a3d0f18-2aff-4dc7-dc28-d35c733da387"
      },
      "source": [
        "data.tail(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1697</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедными родственниками</td>\n",
              "      <td>0</td>\n",
              "      <td>Проходя мимо церквей, я вижу иногда человека,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1698</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедных родственниках</td>\n",
              "      <td>0</td>\n",
              "      <td>[Егор Дмитрич Глумов, муж]   У молодой женщин...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Idiom Normal  ...                                            Example\n",
              "1697  бедный родственник  ...   Проходя мимо церквей, я вижу иногда человека,...\n",
              "1698  бедный родственник  ...   [Егор Дмитрич Глумов, муж]   У молодой женщин...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ37N3KIgXiK",
        "outputId": "528c78c3-7a41-4e2d-b581-c65fcbb1701b"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1699, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBdk00Dfo7zD"
      },
      "source": [
        "## Load BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367,
          "referenced_widgets": [
            "94d340ed7c4f4567b6a9522424cd9028",
            "c2c40cf5776c40e7bdacc42973b880a8",
            "9956555a7a1f48488821b1139ecbf526",
            "99a7bd4a2a04499fb5bd8ef19895b9fa",
            "bffff130fc404e6eae6e609b2a159010",
            "dee218b1b6874f4d9ab130af11e90f21",
            "192d46450bc6433287470c270b9ec9e7",
            "09506d1c7e274a92aadafb4632102704",
            "2c7a1869c1b04c1fa48ecda60da3b1e4",
            "c4f07e3f889643bdb942e710e4e8764d",
            "5d822dbd363d4bb8846d9c88920ae57a",
            "43916718b37d4c26a6cbf26687eaad85",
            "146f9b9ea6e247c4abc6f0a2fdb8e08b",
            "e09ef60f67c3485986adabe6556f2660",
            "3428123910a84dfdb1702b9aa65ee717",
            "ab848434c52144df9cef307c2bcfd4c7",
            "6d03d8857dbc4320af8ed119a052db7e",
            "f00b453dc9994626888d9a3bc32d091d",
            "c6c2b5e9d39b42be8257061374f7d93d",
            "d59a83cb56c14746aed2ba8c39382404",
            "d91341f71d704a7bb32c049ae7697368",
            "e7c4b0c90c9f4935a72caa8479513faf",
            "4b5c94d7846048909190f0c6135b072f",
            "3dbaa8b649fd4cd091e4de1faa5b34ef",
            "1a5ba35122b9427f8a1fd729b1f4a6e4",
            "746cd75c3dac400fbfb7e25edd0e37c4",
            "58ab95843a1d4ed7886bfbe15ed83551",
            "6b0e96fe313a4e9a8922ee6bfc5de446",
            "0a7f42a689984f0b871ce5e8f4b502e2",
            "7586034dbeb14ed99034e308e4ec867b",
            "03ef94f8eaa8491d910542a36280589a",
            "99f4996a7fcf492ca765fca643a49e57",
            "1b4fa0fce91e4763939e8e59e93f1804",
            "83165302c61a4cb09375e91c5ec79d12",
            "d8ffc9d7197d4215bb1b17f8b364d46e",
            "b9c2f6827a2140419d1154b5053f029f",
            "951f3f8db2804f1fb36fab3e41dce537",
            "f00209be668d4e7fb464b9d960b4c7fe",
            "b75ca59b5dcb4a9f979082acd625c0ef",
            "475fa0e02ac74227b2e02190785152be"
          ]
        },
        "id": "R4ohX1k2CneW",
        "outputId": "9a05a034-e9f8-43fa-8c72-9701ba43e20f"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.TFBertModel, ppb.BertTokenizer, 'bert-base-multilingual-cased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "BERT_model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d340ed7c4f4567b6a9522424cd9028",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c7a1869c1b04c1fa48ecda60da3b1e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d03d8857dbc4320af8ed119a052db7e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a5ba35122b9427f8a1fd729b1f4a6e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b4fa0fce91e4763939e8e59e93f1804",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1083389348.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znpna0U06Gf4"
      },
      "source": [
        "def pad_sentence(tokenized, max_len):\n",
        "  print('\\nPadding/truncating all sentences to %d values...' % max_len)\n",
        "  print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "  # Pad our input tokens with value 0.\n",
        "  # \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "  # as opposed to the beginning.\n",
        "  input_ids = pad_sequences(tokenized, maxlen=max_len, dtype=\"long\", \n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "  print('\\nDone.')\n",
        "  return input_ids\n",
        "\n",
        "\n",
        "def create_att_masks(input_ids):\n",
        "  # Create attention masks\n",
        "  attention_masks = []\n",
        "\n",
        "  # For each sentence...\n",
        "  for sent in input_ids:\n",
        "      \n",
        "      # Create the attention mask.\n",
        "      #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "      #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "      att_mask = [int(token_id > 0) for token_id in sent]\n",
        "      \n",
        "      # Store the attention mask for this sentence.\n",
        "      attention_masks.append(att_mask)\n",
        "  attention_masks = np.array(attention_masks)    \n",
        "  return attention_masks\n",
        "\n",
        "def extract_full_embeddings(output):\n",
        "  last_hidden_states = output[0] # lhs for all sentences\n",
        "  extracted = []\n",
        "  for i, el in enumerate(last_hidden_states): #for each sentence...\n",
        "    extracted.append(last_hidden_states[i]) \n",
        "  return extracted\n",
        "\n",
        "def use_batches(padded, masked):\n",
        "  full_embeddings = []\n",
        "\n",
        "  NUM_OF_IDIOMS_initial = len(masked)\n",
        "  BATCH_SIZE = 200  # Using larger batch might kill the session when embedding contexts\n",
        "  NUM_OF_IDIOMS = NUM_OF_IDIOMS_initial\n",
        "  i = 0\n",
        "\n",
        "  while NUM_OF_IDIOMS > 0:\n",
        "    print(i)\n",
        "    NUM_OF_IDIOMS -= BATCH_SIZE\n",
        "    print('NUM_OF_IDIOMS -= BATCH_SIZE', NUM_OF_IDIOMS)\n",
        "    if i < NUM_OF_IDIOMS_initial - BATCH_SIZE:\n",
        "      output_batch = BERT_model(padded[i:i+BATCH_SIZE], attention_mask = masked[i:i+BATCH_SIZE])\n",
        "    else:\n",
        "      output_batch = BERT_model(padded[i:NUM_OF_IDIOMS_initial], attention_mask = masked[i:NUM_OF_IDIOMS_initial])\n",
        "    i += BATCH_SIZE\n",
        "    embeddings_batch = extract_full_embeddings(output_batch)\n",
        "    full_embeddings.append(embeddings_batch)\n",
        "\n",
        "  full_embeddings_all = []\n",
        "  for batch in full_embeddings:\n",
        "    for sentence in batch:\n",
        "      full_embeddings_all.append(sentence)\n",
        "\n",
        "  return full_embeddings_all\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L6K18m7_HUH"
      },
      "source": [
        "## Define RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anvi8xiJ_I7D"
      },
      "source": [
        "MAX_SEQUENCE_LEN = 150\n",
        "VECTOR_DIM = 768\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "  forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "  backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                      go_backwards=True)\n",
        "  model.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                        input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "  model.add(Dense(NUM_CLASSES))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "  print('compiled model')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ2HEOXDguxN"
      },
      "source": [
        "## All Idioms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzJ5yK9iC7jS",
        "outputId": "ca232508-c541-4a93-db67-afcda430e2ac"
      },
      "source": [
        "tokenized_idioms = data['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts = data['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length = max([len(sen) for sen in tokenized_idioms])\n",
        "max_context_length = max([len(sen) for sen in tokenized_contexts])\n",
        "print('Max idiom length: ', max_idiom_length)\n",
        "print('Max context length: ', max_context_length)\n",
        "\n",
        "padded_idioms = pad_sentence(tokenized_idioms, max_idiom_length+5)\n",
        "padded_contexts = pad_sentence(tokenized_contexts, max_context_length+20)\n",
        "print(len(padded_idioms))\n",
        "print(len(padded_contexts))\n",
        "\n",
        "masked_idioms = create_att_masks(padded_idioms)\n",
        "masked_contexts = create_att_masks(padded_contexts)\n",
        "print(len(masked_idioms))\n",
        "print(len(masked_contexts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  234\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 254 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "1699\n",
            "1699\n",
            "1699\n",
            "1699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-l0q4OWDi_g",
        "outputId": "f7b7f88b-f986-4a65-81a8-6ef0137e5df7"
      },
      "source": [
        "embedded_contexts = use_batches(padded_contexts, masked_contexts)\n",
        "len(embedded_contexts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1499\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1299\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1099\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 899\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 699\n",
            "1000\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 499\n",
            "1200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 299\n",
            "1400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 99\n",
            "1600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1699"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TCDbnVy-ooQn",
        "outputId": "c0ba950f-d378-4ce7-8162-f6d0c8137244"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он сгреб кучку золота, прибавил к ней на глаз...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Передо мною все мелькала бледная улыбка банко...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бейте карту</td>\n",
              "      <td>1</td>\n",
              "      <td>Бейте карту: или я, или вы комендантом в замк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1694</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедными родственниками</td>\n",
              "      <td>1</td>\n",
              "      <td>И мы, россиянцы, будем чувствовать себя на эт...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1695</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедными родственниками</td>\n",
              "      <td>1</td>\n",
              "      <td>Скорее, бедными родственниками являются именн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1696</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедными родственниками</td>\n",
              "      <td>0</td>\n",
              "      <td>Александр II с детских лет привык считать бед...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1697</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедными родственниками</td>\n",
              "      <td>0</td>\n",
              "      <td>Проходя мимо церквей, я вижу иногда человека,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1698</th>\n",
              "      <td>бедный родственник</td>\n",
              "      <td>бедных родственниках</td>\n",
              "      <td>0</td>\n",
              "      <td>[Егор Дмитрич Глумов, муж]   У молодой женщин...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1699 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Idiom Normal  ...                                            Example\n",
              "0             бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1             бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "2             бить карту  ...   Он сгреб кучку золота, прибавил к ней на глаз...\n",
              "3             бить карту  ...   Передо мною все мелькала бледная улыбка банко...\n",
              "4             бить карту  ...   Бейте карту: или я, или вы комендантом в замк...\n",
              "...                  ...  ...                                                ...\n",
              "1694  бедный родственник  ...   И мы, россиянцы, будем чувствовать себя на эт...\n",
              "1695  бедный родственник  ...   Скорее, бедными родственниками являются именн...\n",
              "1696  бедный родственник  ...   Александр II с детских лет привык считать бед...\n",
              "1697  бедный родственник  ...   Проходя мимо церквей, я вижу иногда человека,...\n",
              "1698  бедный родственник  ...   [Егор Дмитрич Глумов, муж]   У молодой женщин...\n",
              "\n",
              "[1699 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8wglrGbD48T"
      },
      "source": [
        "labels = to_categorical(data.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOgBSYX8D7BK"
      },
      "source": [
        "X_train, X_test = train_test_split(embedded_contexts, test_size=0.2, random_state=34)\n",
        "Y_train, Y_test = train_test_split(labels, test_size=0.2, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhEfUvMDCJiH"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JYMhfEIXYw",
        "outputId": "001d77fa-4fd8-4c8d-e704-185b0dc53843"
      },
      "source": [
        "model_all = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshn2ysyGgvg",
        "outputId": "6c3378b8-ee49-4838-f284-adaa558985b1"
      },
      "source": [
        "model_all.fit(np.asarray(X_train), Y_train, batch_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_input'), name='masking_input', description=\"created by layer 'masking_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_input'), name='masking_input', description=\"created by layer 'masking_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "170/170 [==============================] - 49s 239ms/step - loss: 0.6055 - accuracy: 0.6909\n",
            "Epoch 2/10\n",
            "170/170 [==============================] - 41s 239ms/step - loss: 0.5049 - accuracy: 0.7586\n",
            "Epoch 3/10\n",
            "170/170 [==============================] - 41s 239ms/step - loss: 0.4621 - accuracy: 0.7822\n",
            "Epoch 4/10\n",
            "170/170 [==============================] - 40s 237ms/step - loss: 0.4232 - accuracy: 0.8124\n",
            "Epoch 5/10\n",
            "170/170 [==============================] - 40s 237ms/step - loss: 0.3935 - accuracy: 0.8227\n",
            "Epoch 6/10\n",
            "170/170 [==============================] - 40s 236ms/step - loss: 0.3521 - accuracy: 0.8492\n",
            "Epoch 7/10\n",
            "170/170 [==============================] - 40s 236ms/step - loss: 0.3214 - accuracy: 0.8668\n",
            "Epoch 8/10\n",
            "170/170 [==============================] - 40s 236ms/step - loss: 0.2876 - accuracy: 0.8749\n",
            "Epoch 9/10\n",
            "170/170 [==============================] - 40s 236ms/step - loss: 0.2714 - accuracy: 0.8756\n",
            "Epoch 10/10\n",
            "170/170 [==============================] - 40s 236ms/step - loss: 0.2324 - accuracy: 0.9014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fab6aba8410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT389s3HGsqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6e109d-3fc1-4081-f084-7b3aed40a50e"
      },
      "source": [
        "model_all.evaluate(np.asarray(X_test), Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "11/11 [==============================] - 4s 106ms/step - loss: 0.6364 - accuracy: 0.7912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6363776922225952, 0.7911764979362488]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nbUO7jhz5U4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b55297d-65b4-4dc0-c3a8-73132d65b4fb"
      },
      "source": [
        "preds_all = model_all.predict(np.array(X_test))\n",
        "f1_score(np.argmax(preds_all, axis=1), np.argmax(Y_test, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_1_input'), name='masking_1_input', description=\"created by layer 'masking_1_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7942028985507246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiLwBBMkKfm4"
      },
      "source": [
        " n_classes = 3\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y_test_anc[:, i], preds_anc[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Qtz4jxj685"
      },
      "source": [
        "## VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdmWWw4j-mv",
        "outputId": "ba57ead4-8f18-4707-e7dc-ae9448ae66ed"
      },
      "source": [
        "tokenized_idioms_vnc = data_vnc['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_vnc = data_vnc['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_vnc = max([len(sen) for sen in tokenized_idioms_vnc])\n",
        "max_context_length_vnc = max([len(sen) for sen in tokenized_contexts_vnc])\n",
        "print('Max idiom length: ', max_idiom_length_vnc)\n",
        "print('Max context length: ', max_context_length_vnc)\n",
        "\n",
        "padded_idioms_vnc = pad_sentence(tokenized_idioms_vnc, max_idiom_length_vnc+5)\n",
        "padded_contexts_vnc = pad_sentence(tokenized_contexts_vnc, max_context_length_vnc+20)\n",
        "print(len(padded_idioms_vnc))\n",
        "print(len(padded_contexts_vnc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  234\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 254 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "893\n",
            "893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko7oWjDGlSiz",
        "outputId": "3c9e2a58-1925-4cd7-80e5-60db0c43dc0f"
      },
      "source": [
        "masked_idioms_vnc = create_att_masks(padded_idioms_vnc)\n",
        "masked_contexts_vnc = create_att_masks(padded_contexts_vnc)\n",
        "print(len(masked_idioms_vnc))\n",
        "print(len(masked_contexts_vnc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "893\n",
            "893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQmv_Onpl_Lt",
        "outputId": "6ba5b56c-ea2d-4aa8-8f6b-cdb1568815b3"
      },
      "source": [
        "embedded_contexts_vnc = use_batches(padded_contexts_vnc, masked_contexts_vnc)\n",
        "len(embedded_contexts_vnc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 693\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 493\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 293\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 93\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrdp7OElmE1o"
      },
      "source": [
        "labels_vnc = to_categorical(data_vnc.Label)\n",
        "X_train_vnc, X_test_vnc = train_test_split(embedded_contexts_vnc, test_size=0.2, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5lUz-Qmm_fq"
      },
      "source": [
        "Y_train_vnc, Y_test_vnc = train_test_split(labels_vnc, test_size=0.2, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H4GbpTTnM8R"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM6TT-6b--Tk",
        "outputId": "26d3a200-6f86-4b18-a1f6-914633f06945"
      },
      "source": [
        "model_vnc = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLwbWdsunZzl",
        "outputId": "9145a5df-42e7-4bdf-aae5-21f6596809b7"
      },
      "source": [
        "model_vnc.fit(np.asarray(X_train_vnc), Y_train_vnc, batch_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_input'), name='masking_input', description=\"created by layer 'masking_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_input'), name='masking_input', description=\"created by layer 'masking_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "90/90 [==============================] - 27s 227ms/step - loss: 0.6189 - accuracy: 0.6597\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 0.4896 - accuracy: 0.7885\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 21s 231ms/step - loss: 0.4268 - accuracy: 0.8025\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 21s 230ms/step - loss: 0.3694 - accuracy: 0.8445\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.3265 - accuracy: 0.8599\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 21s 230ms/step - loss: 0.2719 - accuracy: 0.8838\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 20s 228ms/step - loss: 0.2343 - accuracy: 0.9034\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.2227 - accuracy: 0.9090\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 21s 229ms/step - loss: 0.1841 - accuracy: 0.9300\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 21s 230ms/step - loss: 0.1505 - accuracy: 0.9342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa656a3ca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bZm3Lv3rFfn",
        "outputId": "61542197-29f8-4cb9-e2cb-3adac63b00b3"
      },
      "source": [
        "model_vnc.evaluate(np.asarray(X_test_vnc), Y_test_vnc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_input'), name='masking_input', description=\"created by layer 'masking_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "6/6 [==============================] - 3s 96ms/step - loss: 0.4989 - accuracy: 0.8324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49890008568763733, 0.832402229309082]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kyqIi2QAnZU",
        "outputId": "084fb356-cb71-48aa-db19-c0b6d69f64dd"
      },
      "source": [
        "preds_vnc = model_vnc.predict(np.array(X_test_vnc))\n",
        "f1_score(np.argmax(preds_vnc, axis=1), np.argmax(Y_test_vnc, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_input'), name='masking_input', description=\"created by layer 'masking_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8514851485148516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABSFxZNrNz0"
      },
      "source": [
        "## ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s2TY7DvrMFX",
        "outputId": "cc9f443d-845e-44a8-b1b4-5e4e747ec46e"
      },
      "source": [
        "tokenized_contexts_anc = data_anc['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_context_length_anc = max([len(sen) for sen in tokenized_contexts_anc])\n",
        "print('Max context length: ', max_context_length_anc)\n",
        "\n",
        "padded_contexts_anc = pad_sentence(tokenized_contexts_anc, max_context_length_anc+20)\n",
        "print(len(padded_contexts_anc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max context length:  221\n",
            "\n",
            "Padding/truncating all sentences to 241 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-bTmd94r70n",
        "outputId": "bbf32988-4683-4756-e190-249e438e5ce0"
      },
      "source": [
        "masked_contexts_anc = create_att_masks(padded_contexts_anc)\n",
        "print(len(masked_contexts_anc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFCV9f9AsWUa",
        "outputId": "89f80f54-40a5-4205-a237-8ec301dcaf43"
      },
      "source": [
        "embedded_contexts_anc = use_batches(padded_contexts_anc, masked_contexts_anc)\n",
        "len(embedded_contexts_anc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 606\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 406\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 206\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 6\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEZOe1q8sfQc"
      },
      "source": [
        "labels_anc = to_categorical(data_anc.Label)\n",
        "X_train_anc, X_test_anc = train_test_split(embedded_contexts_anc, test_size=0.2, random_state=34)\n",
        "Y_train_anc, Y_test_anc = train_test_split(labels_anc, test_size=0.2, random_state=34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8vv7_Zks3ge"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe2LfJxJs2Z6",
        "outputId": "02489f05-8dae-44b8-f1e0-42bcf513ac7a"
      },
      "source": [
        "model_anc = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_k9TTCfs7hb",
        "outputId": "01ed7d39-d097-46a3-ad4b-cf41ce4e3ac3"
      },
      "source": [
        "model_anc.fit(np.asarray(X_train_anc), Y_train_anc, batch_size=8, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "81/81 [==============================] - 25s 219ms/step - loss: 0.6665 - accuracy: 0.5978\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 18s 223ms/step - loss: 0.5584 - accuracy: 0.7314\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 18s 219ms/step - loss: 0.4962 - accuracy: 0.7702\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 18s 221ms/step - loss: 0.4379 - accuracy: 0.8090\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 18s 218ms/step - loss: 0.3870 - accuracy: 0.8323\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 18s 218ms/step - loss: 0.3415 - accuracy: 0.8634\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 20s 253ms/step - loss: 0.2965 - accuracy: 0.8882\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 18s 222ms/step - loss: 0.2672 - accuracy: 0.8975\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 18s 219ms/step - loss: 0.2328 - accuracy: 0.9022\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 18s 219ms/step - loss: 0.2094 - accuracy: 0.9161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa644b61510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6txZ7eLitC1R",
        "outputId": "13cb7bce-6601-454d-9798-16c31988d3ea"
      },
      "source": [
        "model_anc.evaluate(np.asarray(X_test_anc), Y_test_anc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "6/6 [==============================] - 3s 83ms/step - loss: 0.6992 - accuracy: 0.7840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6991873383522034, 0.7839506268501282]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JqngCkVR0qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a8760d-2132-47c0-94c8-ffb9ae6d1a31"
      },
      "source": [
        "preds_anc = model_anc.predict(np.array(X_test_anc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 150, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 768), dtype=tf.float32, name='masking_2_input'), name='masking_2_input', description=\"created by layer 'masking_2_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Sa67P46Tdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320b4c1f-3d0b-45d3-e282-eefce89d0567"
      },
      "source": [
        "f1_score(np.argmax(preds_anc, axis=1), np.argmax(Y_test_anc, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7798742138364779"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNs0MSsqSJKl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhXwL5WVeoT"
      },
      "source": [
        "# Not Present in the Training Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Zj87_Ee784"
      },
      "source": [
        "## Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9eWLhEyVp2A",
        "outputId": "dd247fc5-2f0a-435d-83a5-d94a568ad8b3"
      },
      "source": [
        "data_anc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "больное место                 57\n",
              "правая рука                   56\n",
              "болевая точка                 52\n",
              "нож острый                    49\n",
              "путеводная звезда             48\n",
              "лавровый венок                44\n",
              "бедный родственник            41\n",
              "зелёная улица                 38\n",
              "тяжёлая рука                  38\n",
              "ваш брат                      34\n",
              "вавилонское столпотворение    30\n",
              "наша сестра                   28\n",
              "пороховая бочка               27\n",
              "дальний прицел                25\n",
              "заблудшая овца                23\n",
              "вторая ступень                23\n",
              "старый воробей                22\n",
              "красная бумажка               21\n",
              "синяя птица                   20\n",
              "долгая песня                  18\n",
              "другой разговор               18\n",
              "старый гриб                   16\n",
              "чёрная кость                  15\n",
              "девичья кожа                  12\n",
              "маковое зерно                 10\n",
              "избитая дорога                10\n",
              "музейная редкость             10\n",
              "куриная голова                 9\n",
              "ободранная кошка               9\n",
              "чернильная строка              3\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHTExiRhXRyn"
      },
      "source": [
        "test_ancs = ['вавилонское столпотворение', 'ободранная кошка', 'наша сестра', 'пороховая бочка', 'дальний прицел', 'заблудшая овца', 'красная бумажка']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh4qK7yGZjgx",
        "outputId": "b721d1cb-cc80-400c-8dc4-79851095e45c"
      },
      "source": [
        "data_anc_test = data_anc.loc[data_anc['Idiom Normal'].isin(test_ancs)]\n",
        "data_anc_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvId2OZLYrTI",
        "outputId": "180dd360-e49e-4502-c148-d7333a8c385e"
      },
      "source": [
        "data_anc_train = data_anc.loc[~data_anc['Idiom Normal'].isin(test_ancs)]\n",
        "data_anc_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(643, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BDhqDI6aDQB",
        "outputId": "e539859d-4920-4f8b-cf4d-bd0f8c73905c"
      },
      "source": [
        "163/806"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2022332506203474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRPthD1wW72U",
        "outputId": "e0d72869-c60a-4f17-a880-fcb0ce7c900a"
      },
      "source": [
        "data_vnc['Idiom Normal'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "бросать тень               53\n",
              "сесть на мель              47\n",
              "пускать корни              41\n",
              "окунуться с головой        31\n",
              "отвести глаза              29\n",
              "давит грудь                29\n",
              "поставить на колени        29\n",
              "выступить на сцену         27\n",
              "приложить руку             27\n",
              "снимать шляпу              27\n",
              "поднять на ноги            27\n",
              "положить голову            25\n",
              "пахнет порохом             23\n",
              "вырвать с корнем           23\n",
              "точить нож                 22\n",
              "преградить дорогу          22\n",
              "вильнуть хвостом           21\n",
              "сидеть на печи             20\n",
              "открыть глаза              20\n",
              "умывать руки               19\n",
              "открывать Америку          19\n",
              "плести кружева             18\n",
              "взваливать на плечи        17\n",
              "имей глаза                 17\n",
              "поддать жару               16\n",
              "разбить лед                16\n",
              "чесать затылок             16\n",
              "прокладывать дорогу        14\n",
              "бросать перо               14\n",
              "прижать хвост              13\n",
              "давать сдачу               13\n",
              "катить бочку               12\n",
              "прищемить хвост            12\n",
              "поймать на удочку          12\n",
              "держать на прицеле         11\n",
              "поднимать пыль             11\n",
              "сделать выставку           10\n",
              "воскурять фимиам            9\n",
              "наступить на мозоль         8\n",
              "попадать в яблочко          8\n",
              "надеть узду                 8\n",
              "ослепить глаза              8\n",
              "задрать хвост               8\n",
              "положить на обе лопатки     7\n",
              "сжигать мосты               6\n",
              "наступать на ногу           6\n",
              "опустить хвост              5\n",
              "посадить на землю           5\n",
              "бить карту                  5\n",
              "поддаться на удочку         4\n",
              "становиться на рельсы       3\n",
              "Name: Idiom Normal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7zwblUbbu5w"
      },
      "source": [
        "test_vncs = ['точить нож', 'преградить дорогу', 'вильнуть хвостом', 'сидеть на печи', \n",
        "             'открыть глаза', 'умывать руки', 'открывать Америку', 'плести кружева', \n",
        "             'положить голову']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKSFFPdKc0qo",
        "outputId": "c78aa848-374c-4a0f-f9d4-2f390797de8e"
      },
      "source": [
        "data_vnc_test = data_vnc.loc[data_vnc['Idiom Normal'].isin(test_vncs)]\n",
        "data_vnc_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll4Gt0JSc9UB",
        "outputId": "24fb4939-32a1-451a-fad4-46dde6fbe4dc"
      },
      "source": [
        "data_vnc_train = data_vnc.loc[~data_vnc['Idiom Normal'].isin(test_ancs)]\n",
        "data_vnc_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VZA1_6wdLaP",
        "outputId": "53bb7bcf-adf3-4085-f254-678f216b8ebe"
      },
      "source": [
        "186/893"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20828667413213886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "xETJpDLEdPeH",
        "outputId": "ed67fafe-3e35-4fec-f18d-475a99cee79e"
      },
      "source": [
        "data_all_train = pd.concat([data_vnc_train, data_anc_train], ignore_index=True)\n",
        "data_all_train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Он бил карту за картой и загребал золото и кре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>бить карту</td>\n",
              "      <td>бил карту</td>\n",
              "      <td>0</td>\n",
              "      <td>Ермолов держал карты, сощуря правый глаз; ког...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Idiom Normal  ...                                            Example\n",
              "0   бить карту  ...  Он бил карту за картой и загребал золото и кре...\n",
              "1   бить карту  ...   Ермолов держал карты, сощуря правый глаз; ког...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "uIYPXEzXex_y",
        "outputId": "69924d3c-79c8-441e-9b2c-cc107576e1bd"
      },
      "source": [
        "data_all_test = pd.concat([data_vnc_test, data_anc_test], ignore_index=True)\n",
        "data_all_test.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Idiom Normal</th>\n",
              "      <th>Idiom Inflected</th>\n",
              "      <th>Label</th>\n",
              "      <th>Example</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>1</td>\n",
              "      <td>С тех пор от него можно услышать: «Хватит кич...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>открывать Америку</td>\n",
              "      <td>0</td>\n",
              "      <td>Впечатление было такое, что мы на судне Колум...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Idiom Normal  ...                                            Example\n",
              "0  открывать Америку  ...   С тех пор от него можно услышать: «Хватит кич...\n",
              "1  открывать Америку  ...   Впечатление было такое, что мы на судне Колум...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_HkcJsOnGA6"
      },
      "source": [
        "## Embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2dWdUcAofJy"
      },
      "source": [
        "### VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfFmbjdnIOI",
        "outputId": "36fef292-ef12-4117-b808-5e46655a9776"
      },
      "source": [
        "tokenized_idioms_vnc_train_not_present = data_vnc_train['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_vnc_train_not_present = data_vnc_train['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_vnc_train_not_present = max([len(sen) for sen in tokenized_idioms_vnc_train_not_present])\n",
        "max_context_length_vnc_train_not_present = max([len(sen) for sen in tokenized_contexts_vnc_train_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_vnc_train_not_present)\n",
        "print('Max context length: ', max_context_length_vnc_train_not_present)\n",
        "\n",
        "padded_idioms_vnc_train_not_present = pad_sentence(tokenized_idioms_vnc_train_not_present, max_idiom_length_vnc_train_not_present+5)\n",
        "padded_contexts_vnc_train_not_present = pad_sentence(tokenized_contexts_vnc_train_not_present, max_context_length_vnc_train_not_present+20)\n",
        "print(len(padded_idioms_vnc_train_not_present))\n",
        "print(len(padded_contexts_vnc_train_not_present))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  234\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 254 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "893\n",
            "893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM0wsxpunn9y",
        "outputId": "a8dacc18-e4fc-46ee-86bc-709894d55d8a"
      },
      "source": [
        "masked_idioms_vnc_train_not_present = create_att_masks(padded_idioms_vnc_train_not_present)\n",
        "masked_contexts_vnc_train_not_present = create_att_masks(padded_contexts_vnc_train_not_present)\n",
        "print(len(masked_idioms_vnc_train_not_present))\n",
        "print(len(masked_contexts_vnc_train_not_present))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "893\n",
            "893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qAnrcKvoIDL",
        "outputId": "f9b8381b-cac8-44bf-9cfb-2ab83d3af1cb"
      },
      "source": [
        "embedded_idioms_vnc_train_not_present = use_batches(padded_idioms_vnc_train_not_present, masked_idioms_vnc_train_not_present)\n",
        "len(embedded_idioms_vnc_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 693\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 493\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 293\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 93\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWDU4ocUoLWP",
        "outputId": "c9a31903-9040-4272-fd52-cd1723a76c79"
      },
      "source": [
        "embedded_contexts_vnc_train_not_present = use_batches(padded_contexts_vnc_train_not_present, masked_contexts_vnc_train_not_present)\n",
        "len(embedded_contexts_vnc_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 693\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 493\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 293\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 93\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwSGzLy5pjIr"
      },
      "source": [
        "labels_vnc_train_not_present = to_categorical(data_vnc_train.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E259-ehzq74g",
        "outputId": "fcdc28e2-291b-4c49-a972-107c5d9b8121"
      },
      "source": [
        "tokenized_idioms_vnc_test_not_present = data_vnc_test['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_vnc_test_not_present = data_vnc_test['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_vnc_test_not_present = max([len(sen) for sen in tokenized_idioms_vnc_test_not_present])\n",
        "max_context_length_vnc_test_not_present = max([len(sen) for sen in tokenized_contexts_vnc_test_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_vnc_test_not_present)\n",
        "print('Max context length: ', max_context_length_vnc_test_not_present)\n",
        "\n",
        "padded_idioms_vnc_test_not_present = pad_sentence(tokenized_idioms_vnc_test_not_present, max_idiom_length_vnc_test_not_present+5)\n",
        "padded_contexts_vnc_test_not_present = pad_sentence(tokenized_contexts_vnc_test_not_present, max_context_length_vnc_test_not_present+20)\n",
        "print(len(padded_idioms_vnc_test_not_present))\n",
        "print(len(padded_contexts_vnc_test_not_present))\n",
        "\n",
        "masked_idioms_vnc_test_not_present = create_att_masks(padded_idioms_vnc_test_not_present)\n",
        "masked_contexts_vnc_test_not_present = create_att_masks(padded_contexts_vnc_test_not_present)\n",
        "print(len(masked_idioms_vnc_test_not_present))\n",
        "print(len(masked_contexts_vnc_test_not_present))\n",
        "\n",
        "embedded_idioms_vnc_test_not_present = use_batches(padded_idioms_vnc_test_not_present, masked_idioms_vnc_test_not_present)\n",
        "len(embedded_idioms_vnc_test_not_present)\n",
        "\n",
        "embedded_contexts_vnc_test_not_present = use_batches(padded_contexts_vnc_test_not_present, masked_contexts_vnc_test_not_present)\n",
        "len(embedded_contexts_vnc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  10\n",
            "Max context length:  170\n",
            "\n",
            "Padding/truncating all sentences to 15 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 190 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "186\n",
            "186\n",
            "186\n",
            "186\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -14\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLCD8tRut7pf"
      },
      "source": [
        "labels_vnc_test_not_present = to_categorical(data_vnc_test.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNiZNWvfomcL"
      },
      "source": [
        "### ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6ZFvgZxuavk",
        "outputId": "1ea08efe-2019-49c2-a4ea-bc16f1cdfc5b"
      },
      "source": [
        "tokenized_idioms_anc_train_not_present = data_anc_train['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_anc_train_not_present = data_anc_train['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_anc_train_not_present = max([len(sen) for sen in tokenized_idioms_anc_train_not_present])\n",
        "max_context_length_anc_train_not_present = max([len(sen) for sen in tokenized_contexts_anc_train_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_anc_train_not_present)\n",
        "print('Max context length: ', max_context_length_anc_train_not_present)\n",
        "\n",
        "padded_idioms_anc_train_not_present = pad_sentence(tokenized_idioms_anc_train_not_present, max_idiom_length_anc_train_not_present+5)\n",
        "padded_contexts_anc_train_not_present = pad_sentence(tokenized_contexts_anc_train_not_present, max_context_length_anc_train_not_present+20)\n",
        "print(len(padded_idioms_anc_train_not_present))\n",
        "print(len(padded_contexts_anc_train_not_present))\n",
        "\n",
        "masked_idioms_anc_train_not_present = create_att_masks(padded_idioms_anc_train_not_present)\n",
        "masked_contexts_anc_train_not_present = create_att_masks(padded_contexts_anc_train_not_present)\n",
        "print(len(masked_idioms_anc_train_not_present))\n",
        "print(len(masked_contexts_anc_train_not_present))\n",
        "\n",
        "embedded_idioms_anc_train_not_present = use_batches(padded_idioms_anc_train_not_present, masked_idioms_anc_train_not_present)\n",
        "len(embedded_idioms_anc_train_not_present)\n",
        "\n",
        "embedded_contexts_anc_train_not_present = use_batches(padded_contexts_anc_train_not_present, masked_contexts_anc_train_not_present)\n",
        "len(embedded_contexts_anc_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  10\n",
            "Max context length:  221\n",
            "\n",
            "Padding/truncating all sentences to 15 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 241 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "643\n",
            "643\n",
            "643\n",
            "643\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 443\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 243\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 43\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -157\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 443\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 243\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 43\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76_WhQxVuLzp"
      },
      "source": [
        "labels_anc_train_not_present = to_categorical(data_anc_train.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5xjyRsoubhn",
        "outputId": "bfbc3559-b821-4892-8040-a06209fe2310"
      },
      "source": [
        "tokenized_idioms_anc_test_not_present = data_anc_test['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_anc_test_not_present = data_anc_test['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_anc_test_not_present = max([len(sen) for sen in tokenized_idioms_anc_test_not_present])\n",
        "max_context_length_anc_test_not_present = max([len(sen) for sen in tokenized_contexts_anc_test_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_anc_test_not_present)\n",
        "print('Max context length: ', max_context_length_anc_test_not_present)\n",
        "\n",
        "padded_idioms_anc_test_not_present = pad_sentence(tokenized_idioms_anc_test_not_present, max_idiom_length_anc_test_not_present+5)\n",
        "padded_contexts_anc_test_not_present = pad_sentence(tokenized_contexts_anc_test_not_present, max_context_length_anc_test_not_present+20)\n",
        "print(len(padded_idioms_anc_test_not_present))\n",
        "print(len(padded_contexts_anc_test_not_present))\n",
        "\n",
        "masked_idioms_anc_test_not_present = create_att_masks(padded_idioms_anc_test_not_present)\n",
        "masked_contexts_anc_test_not_present = create_att_masks(padded_contexts_anc_test_not_present)\n",
        "print(len(masked_idioms_anc_test_not_present))\n",
        "print(len(masked_contexts_anc_test_not_present))\n",
        "\n",
        "embedded_idioms_anc_test_not_present = use_batches(padded_idioms_anc_test_not_present, masked_idioms_anc_test_not_present)\n",
        "len(embedded_idioms_anc_test_not_present)\n",
        "\n",
        "embedded_contexts_anc_test_not_present = use_batches(padded_contexts_anc_test_not_present, masked_contexts_anc_test_not_present)\n",
        "len(embedded_contexts_anc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  192\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 212 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "163\n",
            "163\n",
            "163\n",
            "163\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -37\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XPmQUstuItS"
      },
      "source": [
        "labels_anc_test_not_present = to_categorical(data_anc_test.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuZbRUd5urYg"
      },
      "source": [
        "### All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDjRZ5jIutP0",
        "outputId": "39a44853-f716-4ea7-ace3-a9d65033e369"
      },
      "source": [
        "tokenized_idioms_all_train_not_present = data_all_train['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_all_train_not_present = data_all_train['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_all_train_not_present = max([len(sen) for sen in tokenized_idioms_all_train_not_present])\n",
        "max_context_length_all_train_not_present = max([len(sen) for sen in tokenized_contexts_all_train_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_all_train_not_present)\n",
        "print('Max context length: ', max_context_length_all_train_not_present)\n",
        "\n",
        "padded_idioms_all_train_not_present = pad_sentence(tokenized_idioms_all_train_not_present, max_idiom_length_all_train_not_present+5)\n",
        "padded_contexts_all_train_not_present = pad_sentence(tokenized_contexts_all_train_not_present, max_context_length_all_train_not_present+20)\n",
        "print(len(padded_idioms_all_train_not_present))\n",
        "print(len(padded_contexts_all_train_not_present))\n",
        "\n",
        "masked_idioms_all_train_not_present = create_att_masks(padded_idioms_all_train_not_present)\n",
        "masked_contexts_all_train_not_present = create_att_masks(padded_contexts_all_train_not_present)\n",
        "print(len(masked_idioms_all_train_not_present))\n",
        "print(len(masked_contexts_all_train_not_present))\n",
        "\n",
        "embedded_idioms_all_train_not_present = use_batches(padded_idioms_all_train_not_present, masked_idioms_all_train_not_present)\n",
        "len(embedded_idioms_all_train_not_present)\n",
        "\n",
        "embedded_contexts_all_train_not_present = use_batches(padded_contexts_all_train_not_present, masked_contexts_all_train_not_present)\n",
        "len(embedded_contexts_all_train_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  234\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 254 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "1536\n",
            "1536\n",
            "1536\n",
            "1536\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1336\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1136\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 936\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 736\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 536\n",
            "1000\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 336\n",
            "1200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 136\n",
            "1400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -64\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1336\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 1136\n",
            "400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 936\n",
            "600\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 736\n",
            "800\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 536\n",
            "1000\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 336\n",
            "1200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 136\n",
            "1400\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32CeHM7wuxO1"
      },
      "source": [
        "labels_all_train_not_present = to_categorical(data_all_train.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFQeYV9Mu0-a",
        "outputId": "72e1e889-48a7-4909-afba-3f1b644b6762"
      },
      "source": [
        "tokenized_idioms_all_test_not_present = data_all_test['Idiom Inflected'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=50)))\n",
        "tokenized_contexts_all_test_not_present = data_all_test['Example'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=500)))\n",
        "max_idiom_length_all_test_not_present = max([len(sen) for sen in tokenized_idioms_all_test_not_present])\n",
        "max_context_length_all_test_not_present = max([len(sen) for sen in tokenized_contexts_all_test_not_present])\n",
        "print('Max idiom length: ', max_idiom_length_all_test_not_present)\n",
        "print('Max context length: ', max_context_length_all_test_not_present)\n",
        "\n",
        "padded_idioms_all_test_not_present = pad_sentence(tokenized_idioms_all_test_not_present, max_idiom_length_all_test_not_present+5)\n",
        "padded_contexts_all_test_not_present = pad_sentence(tokenized_contexts_all_test_not_present, max_context_length_all_test_not_present+20)\n",
        "print(len(padded_idioms_all_test_not_present))\n",
        "print(len(padded_contexts_all_test_not_present))\n",
        "\n",
        "masked_idioms_all_test_not_present = create_att_masks(padded_idioms_all_test_not_present)\n",
        "masked_contexts_all_test_not_present = create_att_masks(padded_contexts_all_test_not_present)\n",
        "print(len(masked_idioms_all_test_not_present))\n",
        "print(len(masked_contexts_all_test_not_present))\n",
        "\n",
        "embedded_idioms_all_test_not_present = use_batches(padded_idioms_all_test_not_present, masked_idioms_all_test_not_present)\n",
        "len(embedded_idioms_all_test_not_present)\n",
        "\n",
        "embedded_contexts_all_test_not_present = use_batches(padded_contexts_all_test_not_present, masked_contexts_all_test_not_present)\n",
        "len(embedded_contexts_all_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max idiom length:  11\n",
            "Max context length:  192\n",
            "\n",
            "Padding/truncating all sentences to 16 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "\n",
            "Padding/truncating all sentences to 212 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n",
            "349\n",
            "349\n",
            "349\n",
            "349\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 149\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -51\n",
            "0\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE 149\n",
            "200\n",
            "NUM_OF_IDIOMS -= BATCH_SIZE -51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhbW6VNZu8r9"
      },
      "source": [
        "labels_all_test_not_present = to_categorical(data_all_test.Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGR3h9qZe_dw"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_WQ4PatxO4Y"
      },
      "source": [
        "### VNC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbu5n0Rhe5KJ",
        "outputId": "ebdbd7e8-a622-4518-8215-46f94d8c1ce1"
      },
      "source": [
        "model_vnc_not_present = Sequential()\n",
        "model_vnc_not_present.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_vnc_not_present.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_vnc_not_present.add(Dense(NUM_CLASSES))\n",
        "model_vnc_not_present.add(Activation('softmax'))\n",
        "\n",
        "model_vnc_not_present.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wlXodaUfQp3",
        "outputId": "41fb6475-3302-403d-f7a8-fdc3d9a112bb"
      },
      "source": [
        "model_vnc_not_present.fit(np.asarray(embedded_contexts_vnc_train_not_present), \n",
        "              labels_vnc_train_not_present, batch_size=8, epochs=10)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_4_input'), name='masking_4_input', description=\"created by layer 'masking_4_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_4_input'), name='masking_4_input', description=\"created by layer 'masking_4_input'\"), but it was called on an input with incompatible shape (None, 254, 768).\n",
            "112/112 [==============================] - 31s 217ms/step - loss: 0.6337 - accuracy: 0.6310\n",
            "Epoch 2/10\n",
            "112/112 [==============================] - 24s 218ms/step - loss: 0.4378 - accuracy: 0.8046\n",
            "Epoch 3/10\n",
            "112/112 [==============================] - 24s 217ms/step - loss: 0.4091 - accuracy: 0.8113\n",
            "Epoch 4/10\n",
            "112/112 [==============================] - 24s 218ms/step - loss: 0.3226 - accuracy: 0.8720\n",
            "Epoch 5/10\n",
            "112/112 [==============================] - 24s 217ms/step - loss: 0.3061 - accuracy: 0.8759\n",
            "Epoch 6/10\n",
            "112/112 [==============================] - 24s 216ms/step - loss: 0.2552 - accuracy: 0.8789\n",
            "Epoch 7/10\n",
            "112/112 [==============================] - 24s 215ms/step - loss: 0.2190 - accuracy: 0.9226\n",
            "Epoch 8/10\n",
            "112/112 [==============================] - 24s 216ms/step - loss: 0.1852 - accuracy: 0.9244\n",
            "Epoch 9/10\n",
            "112/112 [==============================] - 24s 216ms/step - loss: 0.1465 - accuracy: 0.9529\n",
            "Epoch 10/10\n",
            "112/112 [==============================] - 24s 217ms/step - loss: 0.1259 - accuracy: 0.9463\n",
            "fit model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVU6PZjdyaCS",
        "outputId": "5548fcb8-b42c-484a-9bed-1afd5d48d0f8"
      },
      "source": [
        "model_vnc_not_present.evaluate(np.asarray(embedded_contexts_vnc_test_not_present), labels_vnc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_4_input'), name='masking_4_input', description=\"created by layer 'masking_4_input'\"), but it was called on an input with incompatible shape (None, 190, 768).\n",
            "6/6 [==============================] - 3s 72ms/step - loss: 0.1252 - accuracy: 0.9570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12515968084335327, 0.9569892287254333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaPXmKF9ypUW",
        "outputId": "f68fb69f-f6ba-4c4c-d3f8-9855606a26eb"
      },
      "source": [
        "preds_vnc_not_present = model_vnc_not_present.predict(np.array(embedded_contexts_vnc_test_not_present))\n",
        "f1_score(np.argmax(preds_vnc_not_present, axis=1), np.argmax(labels_vnc_test_not_present, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.943661971830986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55pgDltfxRV7"
      },
      "source": [
        "### ANC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzIKtWSPy-Ml",
        "outputId": "50709acd-2148-4adc-a4dd-8fc6b9faa745"
      },
      "source": [
        "model_anc_not_present = Sequential()\n",
        "model_anc_not_present.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_anc_not_present.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_anc_not_present.add(Dense(NUM_CLASSES))\n",
        "model_anc_not_present.add(Activation('softmax'))\n",
        "\n",
        "model_anc_not_present.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k8_IQK0zIht",
        "outputId": "f0bcd097-0091-411d-f2c6-666eda553110"
      },
      "source": [
        "model_anc_not_present.fit(np.asarray(embedded_contexts_anc_train_not_present), \n",
        "              labels_anc_train_not_present, batch_size=8, epochs=10)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 241, 768).\n",
            "81/81 [==============================] - 23s 205ms/step - loss: 0.6829 - accuracy: 0.5610\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.5093 - accuracy: 0.7728\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.4509 - accuracy: 0.8079\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.4196 - accuracy: 0.8005\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.3624 - accuracy: 0.8470\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.3158 - accuracy: 0.8774\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 17s 205ms/step - loss: 0.2712 - accuracy: 0.9077\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.2395 - accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 17s 204ms/step - loss: 0.1902 - accuracy: 0.9419\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 17s 206ms/step - loss: 0.1378 - accuracy: 0.9536\n",
            "fit model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF0DpzSMzO0_",
        "outputId": "8f273cc6-d41b-443d-fa1a-0b62d5bd179d"
      },
      "source": [
        "model_anc_not_present.evaluate(np.asarray(embedded_contexts_anc_test_not_present), labels_anc_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 212, 768).\n",
            "6/6 [==============================] - 3s 69ms/step - loss: 1.2682 - accuracy: 0.5644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2682161331176758, 0.5644171833992004]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGXhVdh_zcvw",
        "outputId": "8b351625-ea61-4e0e-a11e-a5f56e816ea7"
      },
      "source": [
        "preds_anc_not_present = model_anc_not_present.predict(np.array(embedded_contexts_anc_test_not_present))\n",
        "f1_score(np.argmax(preds_anc_not_present, axis=1), np.argmax(labels_anc_test_not_present, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 212, 768).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6077348066298343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3CuvIOzxSpW"
      },
      "source": [
        "### All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prqyDMR3zi5_",
        "outputId": "148cded9-bf45-4ae6-a874-7f5667fc3e13"
      },
      "source": [
        "model_all_not_present = Sequential()\n",
        "model_all_not_present.add(Masking(mask_value=0., input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "forward_layer = GRU(10, return_sequences=False, dropout=0.5)\n",
        "backward_layer = GRU(10, return_sequences=False, dropout=0.5,\n",
        "                    go_backwards=True)\n",
        "model_all_not_present.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "                      input_shape=(MAX_SEQUENCE_LEN,VECTOR_DIM)))\n",
        "model_all_not_present.add(Dense(NUM_CLASSES))\n",
        "model_all_not_present.add(Activation('softmax'))\n",
        "\n",
        "model_all_not_present.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "print('compiled model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compiled model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8ZA-bCRzjHH",
        "outputId": "3019f13c-b1d9-474e-9444-59f94c5f9268"
      },
      "source": [
        "model_all_not_present.fit(np.asarray(embedded_contexts_all_train_not_present), \n",
        "              labels_all_train_not_present, batch_size=8, epochs=10)\n",
        "print('fit model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (8, 254, 768).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (8, 254, 768).\n",
            "192/192 [==============================] - 33s 145ms/step - loss: 0.6494 - accuracy: 0.6351\n",
            "Epoch 2/10\n",
            "192/192 [==============================] - 28s 144ms/step - loss: 0.4975 - accuracy: 0.7652\n",
            "Epoch 3/10\n",
            "192/192 [==============================] - 28s 144ms/step - loss: 0.4495 - accuracy: 0.7829\n",
            "Epoch 4/10\n",
            "192/192 [==============================] - 27s 142ms/step - loss: 0.3941 - accuracy: 0.8253\n",
            "Epoch 5/10\n",
            "192/192 [==============================] - 27s 142ms/step - loss: 0.3771 - accuracy: 0.8389\n",
            "Epoch 6/10\n",
            "192/192 [==============================] - 28s 143ms/step - loss: 0.3301 - accuracy: 0.8648\n",
            "Epoch 7/10\n",
            "192/192 [==============================] - 28s 144ms/step - loss: 0.2957 - accuracy: 0.8809\n",
            "Epoch 8/10\n",
            "192/192 [==============================] - 28s 144ms/step - loss: 0.2910 - accuracy: 0.8754\n",
            "Epoch 9/10\n",
            "192/192 [==============================] - 27s 143ms/step - loss: 0.2493 - accuracy: 0.8928\n",
            "Epoch 10/10\n",
            "192/192 [==============================] - 28s 144ms/step - loss: 0.2359 - accuracy: 0.9115\n",
            "fit model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbNdZnJOzjU0",
        "outputId": "26200c64-4ad4-4593-cab2-b5f6f77ef728"
      },
      "source": [
        "model_all_not_present.evaluate(np.asarray(embedded_contexts_all_test_not_present), labels_all_test_not_present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (None, 212, 768).\n",
            "11/11 [==============================] - 3s 81ms/step - loss: 0.6098 - accuracy: 0.7765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6098086833953857, 0.7765042781829834]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2X2habIzh-g",
        "outputId": "22ff914f-c860-48ec-f45f-facffa7c74c3"
      },
      "source": [
        "preds_all_not_present = model_all_not_present.predict(np.array(embedded_contexts_all_test_not_present))\n",
        "f1_score(np.argmax(preds_all_not_present, axis=1), np.argmax(labels_all_test_not_present, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 500, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (None, 212, 768).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7845303867403315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo82mpfL_Hfu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}